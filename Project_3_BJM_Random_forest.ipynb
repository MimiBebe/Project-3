{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz as gv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_orig = pd.read_csv(os.path.join('data', 'loanDataTest.csv'))\n",
    "pd.set_option('display.max_columns', None)\n",
    "test_data_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_orig = pd.read_csv(os.path.join('data', 'loanDataTrain.csv'))\n",
    "pd.set_option('display.max_columns', None)\n",
    "train_data_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check values in test and train sets\n",
    "test_Gender = test_data_orig.Gender.unique()\n",
    "train_Gender = train_data_orig.Gender.unique()\n",
    "test_Dependents = test_data_orig.Dependents.unique()\n",
    "train_Dependents = train_data_orig.Dependents.unique()\n",
    "test_Education = test_data_orig.Education.unique()\n",
    "train_Education = train_data_orig.Education.unique()\n",
    "test_Self_Employed = test_data_orig.Self_Employed.unique()\n",
    "train_Self_Employed = train_data_orig.Self_Employed.unique()\n",
    "test_ApplicantIncome = test_data_orig.ApplicantIncome.unique()\n",
    "train_ApplicantIncome = train_data_orig.ApplicantIncome.unique()\n",
    "test_CoapplicantIncome = test_data_orig.CoapplicantIncome.unique()\n",
    "train_CoapplicantIncome = train_data_orig.CoapplicantIncome.unique()\n",
    "test_LoanAmount = test_data_orig.LoanAmount.unique()\n",
    "train_LoanAmount = train_data_orig.LoanAmount.unique()\n",
    "test_Loan_Amount_Term = test_data_orig.Loan_Amount_Term.unique()\n",
    "train_Loan_Amount_Term = train_data_orig.Loan_Amount_Term.unique()\n",
    "test_Credit_History = test_data_orig.Credit_History.unique()\n",
    "train_Credit_History = train_data_orig.Credit_History.unique()\n",
    "test_Property_Area = test_data_orig.Property_Area.unique()\n",
    "train_Property_Area = train_data_orig.Property_Area.unique()\n",
    "\n",
    "train_Loan_Status = train_data_orig.Loan_Status.unique()\n",
    "\n",
    "#Print out values\n",
    "#test_Gender, train_Gender, test_Dependents, train_Dependents, test_Education, train_Education, test_Self_Employed, train_Self_Employed, test_ApplicantIncome, train_ApplicantIncome, test_CoapplicantIncome, train_CoapplicantIncome, test_LoanAmount, train_LoanAmount, test_Loan_Amount_Term, train_Loan_Amount_Term, test_Credit_History, train_Credit_History, test_Property_Area, train_Property_Area, train_Loan_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop nans\n",
    "test_data = test_data_orig.dropna(axis=0)\n",
    "train_data_pre_dummy = train_data_orig.dropna(axis=0)\n",
    "\n",
    "test_Gender = test_data.Gender.unique()\n",
    "train_Gender = train_data_pre_dummy.Gender.unique()\n",
    "test_Dependents = test_data.Dependents.unique()\n",
    "train_Dependents = train_data_pre_dummy.Dependents.unique()\n",
    "test_Education = test_data.Education.unique()\n",
    "train_Education = train_data_pre_dummy.Education.unique()\n",
    "test_Self_Employed = test_data.Self_Employed.unique()\n",
    "train_Self_Employed = train_data_pre_dummy.Self_Employed.unique()\n",
    "test_ApplicantIncome = test_data.ApplicantIncome.unique()\n",
    "train_ApplicantIncome = train_data_pre_dummy.ApplicantIncome.unique()\n",
    "test_CoapplicantIncome = test_data.CoapplicantIncome.unique()\n",
    "train_CoapplicantIncome = train_data_pre_dummy.CoapplicantIncome.unique()\n",
    "test_LoanAmount = test_data.LoanAmount.unique()\n",
    "train_LoanAmount = train_data_pre_dummy.LoanAmount.unique()\n",
    "test_Loan_Amount_Term = test_data.Loan_Amount_Term.unique()\n",
    "train_Loan_Amount_Term = train_data_pre_dummy.Loan_Amount_Term.unique()\n",
    "test_Credit_History = test_data.Credit_History.unique()\n",
    "train_Credit_History = train_data_pre_dummy.Credit_History.unique()\n",
    "test_Property_Area = test_data.Property_Area.unique()\n",
    "train_Property_Area = train_data_pre_dummy.Property_Area.unique()\n",
    "\n",
    "train_Loan_Status = train_data_pre_dummy.Loan_Status.unique()\n",
    "\n",
    "#Print out categorical values\n",
    "test_Gender, train_Gender, test_Dependents, train_Dependents, test_Education, train_Education, test_Self_Employed, train_Self_Employed, train_Loan_Amount_Term, test_Credit_History, train_Credit_History, test_Property_Area, train_Property_Area, train_Loan_Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make loan status a dummy variable, drop the \"N\" column\n",
    "train_data = pd.get_dummies(train_data_pre_dummy, prefix=['Loan_Status'], columns=['Loan_Status'])\n",
    "train_data.drop('Loan_Status_N', axis=1, inplace=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More dummy variables\n",
    "train_data_more_dummies = pd.get_dummies(train_data, prefix=['Gender'], columns=['Gender'])\n",
    "train_data_more_dummies.drop('Gender_Male', axis=1, inplace=True)\n",
    "test_data_more_dummies = pd.get_dummies(test_data, prefix=['Gender'], columns=['Gender'])\n",
    "test_data_more_dummies.drop('Gender_Male', axis=1, inplace=True)\n",
    "train_data_more_dummies = pd.get_dummies(train_data_more_dummies, prefix=['Education'], columns=['Education'])\n",
    "train_data_more_dummies.drop('Education_Not Graduate', axis=1, inplace=True)\n",
    "test_data_more_dummies = pd.get_dummies(test_data_more_dummies, prefix=['Education'], columns=['Education'])\n",
    "test_data_more_dummies.drop('Education_Not Graduate', axis=1, inplace=True)\n",
    "train_data_more_dummies = pd.get_dummies(train_data_more_dummies, prefix=['Married'], columns=['Married'])\n",
    "train_data_more_dummies.drop('Married_No', axis=1, inplace=True)\n",
    "test_data_more_dummies = pd.get_dummies(test_data_more_dummies, prefix=['Married'], columns=['Married'])\n",
    "test_data_more_dummies.drop('Married_No', axis=1, inplace=True)\n",
    "train_data_more_dummies = pd.get_dummies(train_data_more_dummies, prefix=['Self_Employed'], columns=['Self_Employed'])\n",
    "train_data_more_dummies.drop('Self_Employed_No', axis=1, inplace=True)\n",
    "test_data_more_dummies = pd.get_dummies(test_data_more_dummies, prefix=['Self_Employed'], columns=['Self_Employed'])\n",
    "test_data_more_dummies.drop('Self_Employed_No', axis=1, inplace=True)\n",
    "train_data_more_dummies = pd.get_dummies(train_data_more_dummies, prefix=['Credit_History'], columns=['Credit_History'])\n",
    "train_data_more_dummies.drop('Credit_History_0.0', axis=1, inplace=True)\n",
    "test_data_more_dummies = pd.get_dummies(test_data_more_dummies, prefix=['Credit_History'], columns=['Credit_History'])\n",
    "test_data_more_dummies.drop('Credit_History_0.0', axis=1, inplace=True)\n",
    "\n",
    "train_data_more_dummies = pd.get_dummies(train_data_more_dummies, prefix=['Property_Area'], columns=['Property_Area'])\n",
    "test_data_more_dummies = pd.get_dummies(test_data_more_dummies, prefix=['Property_Area'], columns=['Property_Area'])\n",
    "\n",
    "train_data_more_dummies = pd.get_dummies(train_data_more_dummies, prefix=['Dependents'], columns=['Dependents'])\n",
    "test_data_more_dummies = pd.get_dummies(test_data_more_dummies, prefix=['Dependents'], columns=['Dependents'])\n",
    "\n",
    "train_data_more_dummies = pd.get_dummies(train_data_more_dummies, prefix=['Loan_Amount_Term'], columns=['Loan_Amount_Term'])\n",
    "test_data_more_dummies = pd.get_dummies(test_data_more_dummies, prefix=['Loan_Amount_Term'], columns=['Loan_Amount_Term'])\n",
    "\n",
    "train_data_more_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Decision Tree: train on randomly split training set with dummies, random_state = 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_more_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data_more_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                      feature_names=feature_names,  \n",
    "                     class_names=target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = gv.Source(dot_data) \n",
    "graph.render(\"first_tree_labeled\") \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decision Tree: train on randomly split training set with dummies, random_state = 57, max_depth = 3 >> Better clf.score than with deeper tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_more_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data_more_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                      feature_names=feature_names,  \n",
    "                     class_names=target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = gv.Source(dot_data) \n",
    "graph.render(\"first_tree_labeled\") \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Tree: train on randomly split training set with dummies, random_state = 57, max_depth = 3, take out Loan_Amount_Term columns other than \"480\" >> no change in clf.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_more_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data_more_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\", 'Loan_Amount_Term_360.0', 'Loan_Amount_Term_180.0', 'Loan_Amount_Term_300.0', 'Loan_Amount_Term_240.0', 'Loan_Amount_Term_60.0', 'Loan_Amount_Term_120.0', 'Loan_Amount_Term_84.0', 'Loan_Amount_Term_36.0'], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                      feature_names=feature_names,  \n",
    "                     class_names=target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = gv.Source(dot_data) \n",
    "graph.render(\"first_tree_labeled\") \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Tree: train on randomly split training set with dummies, random_state = 57, max_depth = 3, take out Loan_Amount_Term  and LoanAmount columns, since these could be considered results: very slight decrease in clf.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_more_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data_more_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\", 'LoanAmount', 'Loan_Amount_Term_480.0', 'Loan_Amount_Term_360.0', 'Loan_Amount_Term_180.0', 'Loan_Amount_Term_300.0', 'Loan_Amount_Term_240.0', 'Loan_Amount_Term_60.0', 'Loan_Amount_Term_120.0', 'Loan_Amount_Term_84.0', 'Loan_Amount_Term_36.0'], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                      feature_names=feature_names,  \n",
    "                     class_names=target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                      special_characters=True)  \n",
    "graph = gv.Source(dot_data) \n",
    "graph.render(\"first_tree_labeled\") \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forest: train on randomly split training set with dummies, random_state = 57, n_estimators = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_more_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_more_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, oob_score = True)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "print('Training score: ', rf.score(X_train, y_train))\n",
    "print('Training score with oob sampling: ', rf.oob_score_)\n",
    "print('Test score: ', rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a random forest classifier with parameter modifications suggested in \n",
    "#https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "rf = RandomForestClassifier(n_estimators=200, oob_score = True, max_features=None, max_depth=None, min_samples_split=2)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "print('Training score, parameters added: ', rf.score(X_train, y_train))\n",
    "print('Training score with oob sampling, parameters added: ', rf.oob_score_)\n",
    "print('Test score, parameters added: ', rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances with added parameters\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest: train on randomly split training set with dummies, random_state = 57, n_estimators = 200, take out Loan_Amount_Term columns other than \"480\" >> no change in test score; 'Credit History' is most important factor, with or without added factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_more_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_more_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\", 'Loan_Amount_Term_360.0', 'Loan_Amount_Term_180.0', 'Loan_Amount_Term_300.0', 'Loan_Amount_Term_240.0', 'Loan_Amount_Term_60.0', 'Loan_Amount_Term_120.0', 'Loan_Amount_Term_84.0', 'Loan_Amount_Term_36.0'], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, oob_score = True)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "print('Training score: ', rf.score(X_train, y_train))\n",
    "print('Training score with oob sampling: ', rf.oob_score_)\n",
    "print('Test score: ', rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a random forest classifier with parameter modifications suggested in \n",
    "#https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "rf = RandomForestClassifier(n_estimators=200, oob_score = True, max_features=None, max_depth=None, min_samples_split=2)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "print('Training score, parameters added: ', rf.score(X_train, y_train))\n",
    "print('Training score with oob sampling, parameters added: ', rf.oob_score_)\n",
    "print('Test score, parameters added: ', rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances with added parameters\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Random Forest: train on randomly split training set with dummies, random_state = 57, n_estimators = 200, take out Loan_Amount_Term  and LoanAmount columns, since these could be considered results >> small decrease in test score, 'Applicant income' and 'Credit History' are the most important factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_more_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_more_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\", 'LoanAmount', 'Loan_Amount_Term_480.0', 'Loan_Amount_Term_360.0', 'Loan_Amount_Term_180.0', 'Loan_Amount_Term_300.0', 'Loan_Amount_Term_240.0', 'Loan_Amount_Term_60.0', 'Loan_Amount_Term_120.0', 'Loan_Amount_Term_84.0', 'Loan_Amount_Term_36.0'], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, oob_score = True)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "print('Training score: ', rf.score(X_train, y_train))\n",
    "print('Training score with oob sampling: ', rf.oob_score_)\n",
    "print('Test score: ', rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a random forest classifier with parameter modifications suggested in \n",
    "#https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "rf = RandomForestClassifier(n_estimators=200, oob_score = True, max_features=None, max_depth=None, min_samples_split=2)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "print('Training score, parameters added: ', rf.score(X_train, y_train))\n",
    "print('Training score with oob sampling, parameters added: ', rf.oob_score_)\n",
    "print('Test score, parameters added: ', rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances with added parameters\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "#max_features=None, max_depth=None, min_samples_split=2 suggested (in this particular case, decreased score by about 0.05)\n",
    "\n",
    "#Also suggest: \"...in random forests, bootstrap samples are used by default (bootstrap=True) while the default strategy for extra-trees is to use the whole dataset (bootstrap=False). When using bootstrap sampling the generalization accuracy can be estimated on the left out or out-of-bag samples. This can be enabled by setting oob_score=True.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Random Forest: train on randomly split training set with dummies, random_state = 57, n_estimators = 200, take out Loan_Amount_Term and LoanAmount columns, also remove columns with importance < 0.03 in both versions of previous run ('Dependents_3+', 'Property_Area_Urban', 'Dependents_2', 'Dependents_1', 'Self_Employed_Yes', 'Gender_Female', 'Property_Area_Rural', 'Dependents_0', 'Property_Area_Semiurban') >> Some decrease in test scores, 'Applicant income' and 'Credit History' remain the most important factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_more_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_more_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\", 'LoanAmount', 'Loan_Amount_Term_480.0', 'Loan_Amount_Term_360.0', 'Loan_Amount_Term_180.0', 'Loan_Amount_Term_300.0', 'Loan_Amount_Term_240.0', 'Loan_Amount_Term_60.0', 'Loan_Amount_Term_120.0', 'Loan_Amount_Term_84.0', 'Loan_Amount_Term_36.0', 'Dependents_3+', 'Property_Area_Urban', 'Dependents_2', 'Dependents_1', 'Self_Employed_Yes', 'Gender_Female', 'Property_Area_Rural', 'Dependents_0', 'Property_Area_Semiurban'], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=200, oob_score = True)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "print('Training score: ', rf.score(X_train, y_train))\n",
    "print('Training score with oob sampling: ', rf.oob_score_)\n",
    "print('Test score: ', rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a random forest classifier with parameter modifications suggested in \n",
    "#https://scikit-learn.org/stable/modules/ensemble.html#forest\n",
    "rf = RandomForestClassifier(n_estimators=200, oob_score = True, max_features=None, max_depth=None, min_samples_split=2)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "print('Training score, parameters added: ', rf.score(X_train, y_train))\n",
    "print('Training score with oob sampling, parameters added: ', rf.oob_score_)\n",
    "print('Test score, parameters added: ', rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine feature importances with added parameters\n",
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
