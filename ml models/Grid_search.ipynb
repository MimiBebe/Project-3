{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_orig = pd.read_csv(os.path.join('data', 'loanDataTest.csv'))\n",
    "pd.set_option('display.max_columns', None)\n",
    "test_data_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data_orig = pd.read_csv(os.path.join('data', 'loanDataTrain.csv'))\n",
    "pd.set_option('display.max_columns', None)\n",
    "train_data_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test_data_orig = pd.read_csv(os.path.join('data', 'loanDataTest.csv'))\n",
    "pd.set_option('display.max_columns', None)\n",
    "test_data_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#train_data_orig = pd.read_csv(os.path.join('data', 'loanDataTrain.csv'))\n",
    "pd.set_option('display.max_columns', None)\n",
    "train_data_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check values in test and train sets\n",
    "test_Gender = test_data_orig.Gender.unique()\n",
    "train_Gender = train_data_orig.Gender.unique()\n",
    "test_Dependents = test_data_orig.Dependents.unique()\n",
    "train_Dependents = train_data_orig.Dependents.unique()\n",
    "test_Education = test_data_orig.Education.unique()\n",
    "train_Education = train_data_orig.Education.unique()\n",
    "test_Self_Employed = test_data_orig.Self_Employed.unique()\n",
    "train_Self_Employed = train_data_orig.Self_Employed.unique()\n",
    "test_ApplicantIncome = test_data_orig.ApplicantIncome.unique()\n",
    "train_ApplicantIncome = train_data_orig.ApplicantIncome.unique()\n",
    "test_CoapplicantIncome = test_data_orig.CoapplicantIncome.unique()\n",
    "train_CoapplicantIncome = train_data_orig.CoapplicantIncome.unique()\n",
    "test_LoanAmount = test_data_orig.LoanAmount.unique()\n",
    "train_LoanAmount = train_data_orig.LoanAmount.unique()\n",
    "test_Loan_Amount_Term = test_data_orig.Loan_Amount_Term.unique()\n",
    "train_Loan_Amount_Term = train_data_orig.Loan_Amount_Term.unique()\n",
    "test_Credit_History = test_data_orig.Credit_History.unique()\n",
    "train_Credit_History = train_data_orig.Credit_History.unique()\n",
    "test_Property_Area = test_data_orig.Property_Area.unique()\n",
    "train_Property_Area = train_data_orig.Property_Area.unique()\n",
    "\n",
    "train_Loan_Status = train_data_orig.Loan_Status.unique()\n",
    "\n",
    "#Print out values\n",
    "#test_Gender, train_Gender, test_Dependents, train_Dependents, test_Education, train_Education, test_Self_Employed, train_Self_Employed, test_ApplicantIncome, train_ApplicantIncome, test_CoapplicantIncome, train_CoapplicantIncome, test_LoanAmount, train_LoanAmount, test_Loan_Amount_Term, train_Loan_Amount_Term, test_Credit_History, train_Credit_History, test_Property_Area, train_Property_Area, train_Loan_Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#drop nans\n",
    "test_data = test_data_orig.dropna(axis=0)\n",
    "train_data_pre_dummy = train_data_orig.dropna(axis=0)\n",
    "\n",
    "test_Gender = test_data.Gender.unique()\n",
    "train_Gender = train_data_pre_dummy.Gender.unique()\n",
    "test_Dependents = test_data.Dependents.unique()\n",
    "train_Dependents = train_data_pre_dummy.Dependents.unique()\n",
    "test_Education = test_data.Education.unique()\n",
    "train_Education = train_data_pre_dummy.Education.unique()\n",
    "test_Self_Employed = test_data.Self_Employed.unique()\n",
    "train_Self_Employed = train_data_pre_dummy.Self_Employed.unique()\n",
    "test_ApplicantIncome = test_data.ApplicantIncome.unique()\n",
    "train_ApplicantIncome = train_data_pre_dummy.ApplicantIncome.unique()\n",
    "test_CoapplicantIncome = test_data.CoapplicantIncome.unique()\n",
    "train_CoapplicantIncome = train_data_pre_dummy.CoapplicantIncome.unique()\n",
    "test_LoanAmount = test_data.LoanAmount.unique()\n",
    "train_LoanAmount = train_data_pre_dummy.LoanAmount.unique()\n",
    "test_Loan_Amount_Term = test_data.Loan_Amount_Term.unique()\n",
    "train_Loan_Amount_Term = train_data_pre_dummy.Loan_Amount_Term.unique()\n",
    "test_Credit_History = test_data.Credit_History.unique()\n",
    "train_Credit_History = train_data_pre_dummy.Credit_History.unique()\n",
    "test_Property_Area = test_data.Property_Area.unique()\n",
    "train_Property_Area = train_data_pre_dummy.Property_Area.unique()\n",
    "\n",
    "train_Loan_Status = train_data_pre_dummy.Loan_Status.unique()\n",
    "\n",
    "#Print out categorical values\n",
    "test_Gender, train_Gender, test_Dependents, train_Dependents, test_Education, train_Education, test_Self_Employed, train_Self_Employed, train_Loan_Amount_Term, test_Credit_History, train_Credit_History, test_Property_Area, train_Property_Area, train_Loan_Status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Make loan status a dummy variable, drop the \"N\" column\n",
    "train_data = pd.get_dummies(train_data_pre_dummy, prefix=['Loan_Status'], columns=['Loan_Status'])\n",
    "train_data.drop('Loan_Status_N', axis=1, inplace=True)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Replace \"3+\" in dependents with \"3\" - not perfect, but easier to deal with\n",
    "train_data = train_data.replace(['3+'],'3')\n",
    "test_data = test_data.replace(['3+'],'3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Limited dummy variables\n",
    "train_data_limit_dummies = pd.get_dummies(train_data, prefix=['Gender'], columns=['Gender'])\n",
    "train_data_limit_dummies.drop('Gender_Male', axis=1, inplace=True)\n",
    "test_data_limit_dummies = pd.get_dummies(test_data, prefix=['Gender'], columns=['Gender'])\n",
    "test_data_limit_dummies.drop('Gender_Male', axis=1, inplace=True)\n",
    "train_data_limit_dummies = pd.get_dummies(train_data_limit_dummies, prefix=['Education'], columns=['Education'])\n",
    "train_data_limit_dummies.drop('Education_Not Graduate', axis=1, inplace=True)\n",
    "test_data_limit_dummies = pd.get_dummies(test_data_limit_dummies, prefix=['Education'], columns=['Education'])\n",
    "test_data_limit_dummies.drop('Education_Not Graduate', axis=1, inplace=True)\n",
    "train_data_limit_dummies = pd.get_dummies(train_data_limit_dummies, prefix=['Married'], columns=['Married'])\n",
    "train_data_limit_dummies.drop('Married_No', axis=1, inplace=True)\n",
    "test_data_limit_dummies = pd.get_dummies(test_data_limit_dummies, prefix=['Married'], columns=['Married'])\n",
    "test_data_limit_dummies.drop('Married_No', axis=1, inplace=True)\n",
    "train_data_limit_dummies = pd.get_dummies(train_data_limit_dummies, prefix=['Self_Employed'], columns=['Self_Employed'])\n",
    "train_data_limit_dummies.drop('Self_Employed_No', axis=1, inplace=True)\n",
    "test_data_limit_dummies = pd.get_dummies(test_data_limit_dummies, prefix=['Self_Employed'], columns=['Self_Employed'])\n",
    "test_data_limit_dummies.drop('Self_Employed_No', axis=1, inplace=True)\n",
    "train_data_limit_dummies = pd.get_dummies(train_data_limit_dummies, prefix=['Credit_History'], columns=['Credit_History'])\n",
    "train_data_limit_dummies.drop('Credit_History_0.0', axis=1, inplace=True)\n",
    "test_data_limit_dummies = pd.get_dummies(test_data_limit_dummies, prefix=['Credit_History'], columns=['Credit_History'])\n",
    "test_data_limit_dummies.drop('Credit_History_0.0', axis=1, inplace=True)\n",
    "\n",
    "train_data_limit_dummies = pd.get_dummies(train_data_limit_dummies, prefix=['Property_Area'], columns=['Property_Area'])\n",
    "test_data_limit_dummies = pd.get_dummies(test_data_limit_dummies, prefix=['Property_Area'], columns=['Property_Area'])\n",
    "\n",
    "train_data_limit_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 (less_dummies) param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]}, random state 33, all columns - some improvement on more_dummies version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_limit_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_limit_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=33)\n",
    "model = SVC(kernel='linear', cache_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 5, 10],\n",
    "              'gamma': [0.0001, 0.001, 0.01]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"Denied\", \"Approved\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 1 (limit dummies) summary\n",
    "\n",
    "GridSearchCV(estimator=SVC(cache_size=1000, kernel='linear'), n_jobs=-1,\n",
    "             param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]},\n",
    "             verbose=3)\n",
    "             \n",
    "Best parameters: {'C': 5, 'gamma': 0.0001}\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "      Denied       0.87      0.33      0.48        39\n",
    "    Approved       0.75      0.98      0.85        81\n",
    "\n",
    "    accuracy                           0.77       120\n",
    "   macro avg       0.81      0.65      0.67       120\n",
    "weighted avg       0.79      0.77      0.73       120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 (less dummies). param_grid={'C': [1, 5, 10], 'gamma': [0.00001, 0.0001, 0.001]}, random state 33, all columns - no discernable change from #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_limit_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_limit_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=33)\n",
    "model = SVC(kernel='linear', cache_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [1, 5, 10],\n",
    "              'gamma': [0.00001, 0.0001, 0.001]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test)\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"Denied\", \"Approved\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 2 (limit dummies) summary\n",
    "\n",
    "GridSearchCV(estimator=SVC(cache_size=1000, kernel='linear'), n_jobs=-1,\n",
    "             param_grid={'C': [1, 5, 10], 'gamma': [1e-05, 0.0001, 0.001]},\n",
    "             verbose=3)\n",
    "Best parameters: {'C': 5, 'gamma': 1e-05}\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "      Denied       0.87      0.33      0.48        39\n",
    "    Approved       0.75      0.98      0.85        81\n",
    "\n",
    "    accuracy                           0.77       120\n",
    "   macro avg       0.81      0.65      0.67       120\n",
    "weighted avg       0.79      0.77      0.73       120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 (less dummies). From https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py: nested vs. non-nested cross-validation -  param_grid={'C': [1, 5, 10], 'gamma': [0.00001, 0.0001, 0.001]} . Non-nested slightly higher, scores a little higher than with data_more_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_limit_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data_limit_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = {\"C\": [1, 5, 10],\n",
    "          \"gamma\": [0.00001, 0.0001, 0.001]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"rbf\", cache_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv, verbose=2, n_jobs=-1)\n",
    "    clf.fit(data, target)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=data, y=target, cv=outer_cv, verbose=2, n_jobs=-1)\n",
    "    nested_scores[i] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_difference = non_nested_scores - nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average difference of {:6f} with std. dev. of {:6f}.\"\n",
    "      .format(score_difference.mean(), score_difference.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "non_nested_scores_line, = plt.plot(non_nested_scores, color='r')\n",
    "nested_line, = plt.plot(nested_scores, color='b')\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend([non_nested_scores_line, nested_line],\n",
    "           [\"Non-Nested CV\", \"Nested CV\"],\n",
    "           bbox_to_anchor=(0, .4, .5, 0))\n",
    "plt.title(\"Non-Nested and Nested Cross Validation on train_data_limit_dummies\",\n",
    "          x=.5, y=1.1, fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend([difference_plot],\n",
    "           [\"Non-Nested CV - Nested CV Score\"],\n",
    "           bbox_to_anchor=(0, 1, .8, 0))\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 3 summary\n",
    "\n",
    "NUM_TRIALS = 30\n",
    "Average difference of 0.006944 with std. dev. of 0.006896."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 (less dummies). Nested vs. non-nested - param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]}. Non-nested slightly higher, scores a little higher than with data_more_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_limit_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_limit_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = {\"C\": [1, 5, 10],\n",
    "          \"gamma\": [0.0001, 0.001, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"rbf\", cache_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv, verbose=2, n_jobs=-1)\n",
    "    clf.fit(data, target)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=data, y=target, cv=outer_cv, verbose=2, n_jobs=-1)\n",
    "    nested_scores[i] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_difference = non_nested_scores - nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average difference of {:6f} with std. dev. of {:6f}.\"\n",
    "      .format(score_difference.mean(), score_difference.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "non_nested_scores_line, = plt.plot(non_nested_scores, color='r')\n",
    "nested_line, = plt.plot(nested_scores, color='b')\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend([non_nested_scores_line, nested_line],\n",
    "           [\"Non-Nested CV\", \"Nested CV\"],\n",
    "           bbox_to_anchor=(0, .4, .5, 0))\n",
    "plt.title(\"Non-Nested and Nested Cross Validation on train_data_limit_dummies\",\n",
    "          x=.5, y=1.1, fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend([difference_plot],\n",
    "           [\"Non-Nested CV - Nested CV Score\"],\n",
    "           bbox_to_anchor=(0, 1, .8, 0))\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 4 summary\n",
    "\n",
    "NUM_TRIALS = 30\n",
    "Average difference of 0.008819 with std. dev. of 0.004862."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 (limit_dummies). Nested vs. non-nested - param_grid={'C': [1, 5, 10], 'gamma':  [0.00001, 0.0001, 0.001]}: As in #3, but with SVC(kernel=\"linear\") rather than rbf -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and parameters\n",
    "NUM_TRIALS = 30\n",
    "target = train_data_limit_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_limit_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\"], axis=1)\n",
    "feature_names = data.columns\n",
    "p_grid = {\"C\": [1, 5, 10],\n",
    "          \"gamma\": [0.00001, 0.0001, 0.001]}\n",
    "svm = SVC(kernel=\"linear\", cache_size=1000)\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv, verbose=2, n_jobs=-1)\n",
    "    clf.fit(data, target)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=data, y=target, cv=outer_cv, verbose=2, n_jobs=-1)\n",
    "    nested_scores[i] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_difference = non_nested_scores - nested_scores\n",
    "print(\"Average difference of {:6f} with std. dev. of {:6f}.\"\n",
    "      .format(score_difference.mean(), score_difference.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "non_nested_scores_line, = plt.plot(non_nested_scores, color='r')\n",
    "nested_line, = plt.plot(nested_scores, color='b')\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend([non_nested_scores_line, nested_line],\n",
    "           [\"Non-Nested CV\", \"Nested CV\"],\n",
    "           bbox_to_anchor=(0, .4, .5, 0))\n",
    "plt.title(\"Non-Nested and Nested Cross Validation on train_data_limit_dummies\",\n",
    "          x=.5, y=1.1, fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend([difference_plot],\n",
    "           [\"Non-Nested CV - Nested CV Score\"],\n",
    "           bbox_to_anchor=(0, 1, .8, 0))\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 5 summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 (limited dummies). As #4 but with scaling and larger cache size. Nested vs. non-nested - param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01]}, kernel = rbf: No nested/non-nested difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/svm.html#svm-classification Kernel cache size: For SVC, SVR, NuSVC and NuSVR, the size of the kernel cache has a strong impact on run times for larger problems. If you have enough RAM available, it is recommended to set cache_size to a higher value than the default of 200(MB), such as 500(MB) or 1000(MB). \n",
    "\n",
    "With 64 GB, I'd say I could go higher on the next run.\n",
    "\n",
    "Support Vector Machine algorithms are not scale invariant, so it is highly recommended to scale your data. REDO AT LEAST FOR MODELS THAT RUN In REASONABLE TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_limit_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_limit_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaler = MinMaxScaler().fit(data)\n",
    "data_scaled = data_scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = {\"C\": [1, 5, 10],\n",
    "          \"gamma\": [0.0001, 0.001, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"rbf\", cache_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv, verbose=2, n_jobs=-1)\n",
    "    clf.fit(data_scaled, target)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=data_scaled, y=target, cv=outer_cv, verbose=2, n_jobs=-1)\n",
    "    nested_scores[i] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_difference = non_nested_scores - nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average difference of {:6f} with std. dev. of {:6f}.\"\n",
    "      .format(score_difference.mean(), score_difference.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "non_nested_scores_line, = plt.plot(non_nested_scores, color='r')\n",
    "nested_line, = plt.plot(nested_scores, color='b')\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend([non_nested_scores_line, nested_line],\n",
    "           [\"Non-Nested CV\", \"Nested CV\"],\n",
    "           bbox_to_anchor=(0, .4, .5, 0))\n",
    "plt.title(\"Non-Nested and Nested Cross Validation on train_data_limit_dummies\",\n",
    "          x=.5, y=1.1, fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend([difference_plot],\n",
    "           [\"Non-Nested CV - Nested CV Score\"],\n",
    "           bbox_to_anchor=(0, 1, .8, 0))\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run 6 summary\n",
    "NUM_TRIALS = 30\n",
    "Average difference of 0.000208 with std. dev. of 0.001122."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 (limited dummies). As #6 (limited dummies) but kernel=\"linear\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_limit_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_limit_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\"], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaler = MinMaxScaler().fit(data)\n",
    "data_scaled = data_scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = {\"C\": [1, 5, 10],\n",
    "          \"gamma\": [0.0001, 0.001, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"linear\", cache_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv, verbose=2, n_jobs=-1)\n",
    "    clf.fit(data_scaled, target)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=data_scaled, y=target, cv=outer_cv, verbose=2, n_jobs=-1)\n",
    "    nested_scores[i] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_difference = non_nested_scores - nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average difference of {:6f} with std. dev. of {:6f}.\"\n",
    "      .format(score_difference.mean(), score_difference.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "non_nested_scores_line, = plt.plot(non_nested_scores, color='r')\n",
    "nested_line, = plt.plot(nested_scores, color='b')\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend([non_nested_scores_line, nested_line],\n",
    "           [\"Non-Nested CV\", \"Nested CV\"],\n",
    "           bbox_to_anchor=(0, .4, .5, 0))\n",
    "plt.title(\"Non-Nested and Nested Cross Validation on train_data_limit_dummies\",\n",
    "          x=.5, y=1.1, fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend([difference_plot],\n",
    "           [\"Non-Nested CV - Nested CV Score\"],\n",
    "           bbox_to_anchor=(0, 1, .8, 0))\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run 7 summary\n",
    "NUM_TRIALS = 30\n",
    "Average difference of 0.000000 with std. dev. of 0.000000.\n",
    "Guess nested vs. not doesn't matter for linear as opposed to rbf, or anyway not here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 (limited dummies). As #7 (limited dummies) but starting with data edits: take out Loan_Amount_Term column. Scores overall a bit lower than in 7. No nested/non-nested difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_limit_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_limit_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\", 'Loan_Amount_Term'], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaler = MinMaxScaler().fit(data)\n",
    "data_scaled = data_scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = {\"C\": [1, 5, 10],\n",
    "          \"gamma\": [0.0001, 0.001, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"linear\", cache_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv, verbose=2, n_jobs=-1)\n",
    "    clf.fit(data_scaled, target)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=data_scaled, y=target, cv=outer_cv, verbose=2, n_jobs=-1)\n",
    "    nested_scores[i] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_difference = non_nested_scores - nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average difference of {:6f} with std. dev. of {:6f}.\"\n",
    "      .format(score_difference.mean(), score_difference.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "non_nested_scores_line, = plt.plot(non_nested_scores, color='r')\n",
    "nested_line, = plt.plot(nested_scores, color='b')\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend([non_nested_scores_line, nested_line],\n",
    "           [\"Non-Nested CV\", \"Nested CV\"],\n",
    "           bbox_to_anchor=(0, .4, .5, 0))\n",
    "plt.title(\"Non-Nested and Nested Cross Validation on train_data_limit_dummies\",\n",
    "          x=.5, y=1.1, fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend([difference_plot],\n",
    "           [\"Non-Nested CV - Nested CV Score\"],\n",
    "           bbox_to_anchor=(0, 1, .8, 0))\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run 8 summary: Scores overall are a bit lower than in 7. Where nested/non-nested differ, non-nested is slightly higher.\n",
    "NUM_TRIALS = 30\n",
    "Average difference of 0.000625 with std. dev. of 0.001096."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 (limited dummies). As #8 (limited dummies) but further data edits: take out Loan_Amount_Term and LoanAmount columns, since these could be considered results. No nested/non-nested difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRIALS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_data_limit_dummies[\"Loan_Status_Y\"]\n",
    "target_names = [\"Denied\", \"Approved\"]\n",
    "data = train_data_limit_dummies.drop([\"Loan_Status_Y\", \"Loan_ID\", 'LoanAmount', 'Loan_Amount_Term'], axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaler = MinMaxScaler().fit(data)\n",
    "data_scaled = data_scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_grid = {\"C\": [1, 5, 10],\n",
    "          \"gamma\": [0.0001, 0.001, 0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel=\"linear\", cache_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv, verbose=2, n_jobs=-1)\n",
    "    clf.fit(data_scaled, target)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    nested_score = cross_val_score(clf, X=data_scaled, y=target, cv=outer_cv, verbose=2, n_jobs=-1)\n",
    "    nested_scores[i] = nested_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_difference = non_nested_scores - nested_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average difference of {:6f} with std. dev. of {:6f}.\"\n",
    "      .format(score_difference.mean(), score_difference.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "non_nested_scores_line, = plt.plot(non_nested_scores, color='r')\n",
    "nested_line, = plt.plot(nested_scores, color='b')\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend([non_nested_scores_line, nested_line],\n",
    "           [\"Non-Nested CV\", \"Nested CV\"],\n",
    "           bbox_to_anchor=(0, .4, .5, 0))\n",
    "plt.title(\"Non-Nested and Nested Cross Validation on train_data_limit_dummies\",\n",
    "          x=.5, y=1.1, fontsize=\"15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend([difference_plot],\n",
    "           [\"Non-Nested CV - Nested CV Score\"],\n",
    "           bbox_to_anchor=(0, 1, .8, 0))\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 9 summary: \n",
    "NUM_TRIALS = 30\n",
    "Scores overall a tiny bit lower than for models with more columns, no difference between nested and non-nested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
