{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.17022005e-01, 7.20324493e-01, 1.14374817e-04])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "#wanted to take a look\n",
    "np.random.rand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow\n",
    "tensorflow.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up multiworker runs would be a bit more work here, see: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>TotalIncome</th>\n",
       "      <th>LogTotalIncome</th>\n",
       "      <th>LogLoanAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5720.0</td>\n",
       "      <td>8.651724</td>\n",
       "      <td>11.608236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4576.0</td>\n",
       "      <td>8.428581</td>\n",
       "      <td>11.744037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>208000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6800.0</td>\n",
       "      <td>8.824678</td>\n",
       "      <td>12.245293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>2546.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4886.0</td>\n",
       "      <td>8.494129</td>\n",
       "      <td>11.512925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>8.094378</td>\n",
       "      <td>11.264464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4009.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5786.0</td>\n",
       "      <td>8.663196</td>\n",
       "      <td>11.635143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4158.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4867.0</td>\n",
       "      <td>8.490233</td>\n",
       "      <td>11.652687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5243.0</td>\n",
       "      <td>8.564649</td>\n",
       "      <td>11.744037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7393.0</td>\n",
       "      <td>8.908289</td>\n",
       "      <td>11.970350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9200.0</td>\n",
       "      <td>9.126959</td>\n",
       "      <td>11.492723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0         0        1           0          1              0           5720.0   \n",
       "1         0        1           1          1              0           3076.0   \n",
       "2         0        1           2          1              0           5000.0   \n",
       "3         0        1           2          1              0           2340.0   \n",
       "4         0        0           0          0              0           3276.0   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "340       0        1           3          0              1           4009.0   \n",
       "341       0        1           0          1              0           4158.0   \n",
       "342       0        0           0          1              0           3250.0   \n",
       "343       0        1           0          1              0           5000.0   \n",
       "344       0        0           0          1              1           9200.0   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                  0.0    110000.0             360.0               1   \n",
       "1               1500.0    126000.0             360.0               1   \n",
       "2               1800.0    208000.0             360.0               1   \n",
       "3               2546.0    100000.0             360.0               0   \n",
       "4                  0.0     78000.0             360.0               1   \n",
       "..                 ...         ...               ...             ...   \n",
       "340             1777.0    113000.0             360.0               1   \n",
       "341              709.0    115000.0             360.0               1   \n",
       "342             1993.0    126000.0             360.0               0   \n",
       "343             2393.0    158000.0             360.0               1   \n",
       "344                0.0     98000.0             180.0               1   \n",
       "\n",
       "     Property_Area  TotalIncome  LogTotalIncome  LogLoanAmount  \n",
       "0                2       5720.0        8.651724      11.608236  \n",
       "1                2       4576.0        8.428581      11.744037  \n",
       "2                2       6800.0        8.824678      12.245293  \n",
       "3                2       4886.0        8.494129      11.512925  \n",
       "4                2       3276.0        8.094378      11.264464  \n",
       "..             ...          ...             ...            ...  \n",
       "340              2       5786.0        8.663196      11.635143  \n",
       "341              2       4867.0        8.490233      11.652687  \n",
       "342              1       5243.0        8.564649      11.744037  \n",
       "343              0       7393.0        8.908289      11.970350  \n",
       "344              0       9200.0        9.126959      11.492723  \n",
       "\n",
       "[345 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import test data file, add columns for log-transformed data\n",
    "test_data = pd.read_csv(os.path.join('../data', 'cleanLoanDataValidationAllIncome.csv'))\n",
    "test_data['LogTotalIncome']=np.log(test_data['TotalIncome'])\n",
    "test_data[\"LogLoanAmount\"]= np.log(test_data[\"LoanAmount\"])\n",
    "pd.set_option('display.max_columns', None)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>TotalIncome</th>\n",
       "      <th>LogTotalIncome</th>\n",
       "      <th>LogLoanAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4583.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6091.0</td>\n",
       "      <td>8.714568</td>\n",
       "      <td>11.759786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>11.097410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4941.0</td>\n",
       "      <td>8.505323</td>\n",
       "      <td>11.695247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>8.699515</td>\n",
       "      <td>11.856515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5417.0</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9613.0</td>\n",
       "      <td>9.170872</td>\n",
       "      <td>12.495004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>7.972466</td>\n",
       "      <td>11.170435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4106.0</td>\n",
       "      <td>8.320205</td>\n",
       "      <td>10.596635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8072.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8312.0</td>\n",
       "      <td>9.025456</td>\n",
       "      <td>12.441145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7583.0</td>\n",
       "      <td>8.933664</td>\n",
       "      <td>12.138864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4583.0</td>\n",
       "      <td>8.430109</td>\n",
       "      <td>11.798104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>563 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0         0        1           1          1              0           4583.0   \n",
       "1         0        1           0          1              1           3000.0   \n",
       "2         0        1           0          0              0           2583.0   \n",
       "3         0        0           0          1              0           6000.0   \n",
       "4         0        1           2          1              1           5417.0   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "558       1        0           0          1              0           2900.0   \n",
       "559       0        1           3          1              0           4106.0   \n",
       "560       0        1           1          1              0           8072.0   \n",
       "561       0        1           2          1              0           7583.0   \n",
       "562       1        0           0          1              1           4583.0   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0               1508.0    128000.0             360.0               1   \n",
       "1                  0.0     66000.0             360.0               1   \n",
       "2               2358.0    120000.0             360.0               1   \n",
       "3                  0.0    141000.0             360.0               1   \n",
       "4               4196.0    267000.0             360.0               1   \n",
       "..                 ...         ...               ...             ...   \n",
       "558                0.0     71000.0             360.0               1   \n",
       "559                0.0     40000.0             180.0               1   \n",
       "560              240.0    253000.0             360.0               1   \n",
       "561                0.0    187000.0             360.0               1   \n",
       "562                0.0    133000.0             360.0               0   \n",
       "\n",
       "     Property_Area  Loan_Status  TotalIncome  LogTotalIncome  LogLoanAmount  \n",
       "0                0            0       6091.0        8.714568      11.759786  \n",
       "1                2            1       3000.0        8.006368      11.097410  \n",
       "2                2            1       4941.0        8.505323      11.695247  \n",
       "3                2            1       6000.0        8.699515      11.856515  \n",
       "4                2            1       9613.0        9.170872      12.495004  \n",
       "..             ...          ...          ...             ...            ...  \n",
       "558              0            1       2900.0        7.972466      11.170435  \n",
       "559              0            1       4106.0        8.320205      10.596635  \n",
       "560              2            1       8312.0        9.025456      12.441145  \n",
       "561              2            1       7583.0        8.933664      12.138864  \n",
       "562              1            0       4583.0        8.430109      11.798104  \n",
       "\n",
       "[563 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import training data file, add columns for log-transformed data\n",
    "train_data = pd.read_csv(os.path.join('../data', 'cleanLoanDataTrainAllIncome.csv'))\n",
    "train_data['LogTotalIncome']=np.log(train_data['TotalIncome'])\n",
    "train_data[\"LogLoanAmount\"]= np.log(train_data[\"LoanAmount\"])\n",
    "pd.set_option('display.max_columns', None)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a: Total income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 10) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'LogTotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=10))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,402\n",
      "Trainable params: 11,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.5776 - accuracy: 0.7014\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5474 - accuracy: 0.7227\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5396 - accuracy: 0.7678\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5292 - accuracy: 0.7678\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5234 - accuracy: 0.7678\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5179 - accuracy: 0.7678\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5182 - accuracy: 0.7701\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5115 - accuracy: 0.7773\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5121 - accuracy: 0.7749\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5118 - accuracy: 0.7678\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5101 - accuracy: 0.7773\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5033 - accuracy: 0.7796\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5020 - accuracy: 0.7749\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4994 - accuracy: 0.7773\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4971 - accuracy: 0.7796\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4965 - accuracy: 0.7820\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4953 - accuracy: 0.7796\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4979 - accuracy: 0.7820\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4956 - accuracy: 0.7844\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4948 - accuracy: 0.7749\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4915 - accuracy: 0.7796\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4870 - accuracy: 0.7820\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4884 - accuracy: 0.7796\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4840 - accuracy: 0.7891\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4796 - accuracy: 0.7867\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4753 - accuracy: 0.7844\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4756 - accuracy: 0.7867\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4727 - accuracy: 0.7938\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4711 - accuracy: 0.7891\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4692 - accuracy: 0.7891\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4701 - accuracy: 0.7891\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4643 - accuracy: 0.8009\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4662 - accuracy: 0.7962\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4629 - accuracy: 0.7915\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4593 - accuracy: 0.8081\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4521 - accuracy: 0.8033\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4676 - accuracy: 0.8033\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4499 - accuracy: 0.8057\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4507 - accuracy: 0.8081\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4543 - accuracy: 0.8057\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4531 - accuracy: 0.8033\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4439 - accuracy: 0.8009\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4406 - accuracy: 0.7986\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4417 - accuracy: 0.8175\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4347 - accuracy: 0.8128\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4457 - accuracy: 0.8081\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4336 - accuracy: 0.8152\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4299 - accuracy: 0.8128\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4332 - accuracy: 0.8081\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4236 - accuracy: 0.8152\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4202 - accuracy: 0.8128\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4190 - accuracy: 0.8175\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4188 - accuracy: 0.8199\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4175 - accuracy: 0.8199\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4283 - accuracy: 0.8199\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4123 - accuracy: 0.8199\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4090 - accuracy: 0.8152\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4117 - accuracy: 0.8152\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4124 - accuracy: 0.8246\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4038 - accuracy: 0.8270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8c087a4c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5360 - accuracy: 0.7021\n",
      "Normal Neural Network 1a - Loss: 0.6198194506743275, Accuracy: 0.7021276354789734\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1a - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1a results\n",
    "\n",
    "Model: \"sequential\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense (Dense)                (None, 100)               1100      \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_2 (Dense)              (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,402\n",
    "Trainable params: 11,402\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 0.5977 - accuracy: 0.7021\n",
    "Normal Neural Network 1a - Loss: 0.6939695828349878, Accuracy: 0.7021276354789734"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b: Separate income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 11) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", \"TotalIncome\", \"LogLoanAmount\", 'LogTotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,502\n",
      "Trainable params: 11,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6172 - accuracy: 0.6777\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5673 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5486 - accuracy: 0.7085\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5345 - accuracy: 0.7488\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5227 - accuracy: 0.7536\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5197 - accuracy: 0.7654\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5107 - accuracy: 0.7701\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5086 - accuracy: 0.7725\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5051 - accuracy: 0.7701\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5042 - accuracy: 0.7701\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.4995 - accuracy: 0.7725\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.4958 - accuracy: 0.7820\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.4969 - accuracy: 0.7844\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4977 - accuracy: 0.7796\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4979 - accuracy: 0.7796\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4996 - accuracy: 0.7867\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4836 - accuracy: 0.7915\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4832 - accuracy: 0.7915\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4790 - accuracy: 0.7986\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4765 - accuracy: 0.7986\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4728 - accuracy: 0.7915\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4704 - accuracy: 0.7986\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4653 - accuracy: 0.8009\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4637 - accuracy: 0.7915\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4615 - accuracy: 0.8009\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4690 - accuracy: 0.8081\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4585 - accuracy: 0.7962\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4547 - accuracy: 0.8081\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4452 - accuracy: 0.8081\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4450 - accuracy: 0.8009\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4483 - accuracy: 0.8152\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4402 - accuracy: 0.8199\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4364 - accuracy: 0.8081\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4291 - accuracy: 0.8152\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4243 - accuracy: 0.8199\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4202 - accuracy: 0.8223\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4170 - accuracy: 0.8223\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4147 - accuracy: 0.8294\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4173 - accuracy: 0.8318\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4110 - accuracy: 0.8270\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4039 - accuracy: 0.8318\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4069 - accuracy: 0.8270\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4018 - accuracy: 0.8412\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.3936 - accuracy: 0.8412\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.3962 - accuracy: 0.8246\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.3927 - accuracy: 0.8341\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.3852 - accuracy: 0.8389\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.3825 - accuracy: 0.8460\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.3815 - accuracy: 0.8412\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.3759 - accuracy: 0.8507\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.3774 - accuracy: 0.8436\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.3719 - accuracy: 0.8507\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.3688 - accuracy: 0.8483\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.3664 - accuracy: 0.8483\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.3716 - accuracy: 0.8460\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.3670 - accuracy: 0.8460\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3729 - accuracy: 0.8412\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3657 - accuracy: 0.8507\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3582 - accuracy: 0.8507\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3540 - accuracy: 0.8531\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bf8abdb38>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.6425 - accuracy: 0.6809\n",
      "Normal Neural Network 1b - Loss: 0.7497691723471838, Accuracy: 0.6808510422706604\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1b - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b results\n",
    "Model: \"sequential_5\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_16 (Dense)             (None, 100)               1200      \n",
    "_________________________________________________________________\n",
    "dense_17 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_18 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,502\n",
    "Trainable params: 11,502\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.5967 - accuracy: 0.6879\n",
    "Normal Neural Network 1 - Loss: 0.6984488072124779, Accuracy: 0.6879432797431946"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c: log(TotalIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 10) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'TotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=10))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,402\n",
      "Trainable params: 11,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.5807 - accuracy: 0.7014\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5512 - accuracy: 0.7109\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5360 - accuracy: 0.7417\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5287 - accuracy: 0.7630\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5207 - accuracy: 0.7796\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5135 - accuracy: 0.7725\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5129 - accuracy: 0.7725\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5090 - accuracy: 0.7820\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5117 - accuracy: 0.7749\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5061 - accuracy: 0.7773\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5010 - accuracy: 0.7773\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5004 - accuracy: 0.7796\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.4959 - accuracy: 0.7796\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4941 - accuracy: 0.7820\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4926 - accuracy: 0.7773\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4893 - accuracy: 0.7796\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4888 - accuracy: 0.7796\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4901 - accuracy: 0.7867\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4813 - accuracy: 0.7820\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4797 - accuracy: 0.7867\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4795 - accuracy: 0.7915\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4755 - accuracy: 0.7867\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4769 - accuracy: 0.7891\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4695 - accuracy: 0.7962\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4657 - accuracy: 0.7915\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4666 - accuracy: 0.7867\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4630 - accuracy: 0.7962\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4606 - accuracy: 0.7938\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4624 - accuracy: 0.7962\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4575 - accuracy: 0.7986\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4550 - accuracy: 0.7962\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4466 - accuracy: 0.7986\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4508 - accuracy: 0.7986\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4571 - accuracy: 0.8081\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4437 - accuracy: 0.8033\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4384 - accuracy: 0.8081\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4379 - accuracy: 0.8081\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4339 - accuracy: 0.8104\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4311 - accuracy: 0.8175\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4384 - accuracy: 0.8270\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4330 - accuracy: 0.8104\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4264 - accuracy: 0.8246\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4280 - accuracy: 0.8175\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4225 - accuracy: 0.8081\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4214 - accuracy: 0.8223\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4236 - accuracy: 0.8270\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4107 - accuracy: 0.8223\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4076 - accuracy: 0.8270\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4106 - accuracy: 0.8223\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4045 - accuracy: 0.8270\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4056 - accuracy: 0.8246\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4022 - accuracy: 0.8270\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.3976 - accuracy: 0.8294\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4057 - accuracy: 0.8246\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.3911 - accuracy: 0.8365\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.3950 - accuracy: 0.8365\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3912 - accuracy: 0.8412\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3846 - accuracy: 0.8318\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3821 - accuracy: 0.8436\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3811 - accuracy: 0.8412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bd09663c8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.6126 - accuracy: 0.6809\n",
      "Normal Neural Network 1c - Loss: 0.7134639405189677, Accuracy: 0.6808510422706604\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1c - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 1c result\n",
    "\n",
    "Model: \"sequential_2\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_6 (Dense)              (None, 100)               1100      \n",
    "_________________________________________________________________\n",
    "dense_7 (Dense)              (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_8 (Dense)              (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,402\n",
    "Trainable params: 11,402\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 0.5485 - accuracy: 0.6950\n",
    "Normal Neural Network 1c - Loss: 0.6729868354526818, Accuracy: 0.695035457611084\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1d: log(TotalIncome), log(LoanAmount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 10) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", \"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", 'TotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=10))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,402\n",
      "Trainable params: 11,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6341 - accuracy: 0.6540\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5800 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5578 - accuracy: 0.7227\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5426 - accuracy: 0.7393\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5276 - accuracy: 0.7630\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5197 - accuracy: 0.7749\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5146 - accuracy: 0.7725\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5119 - accuracy: 0.7773\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5131 - accuracy: 0.7678\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5096 - accuracy: 0.7820\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5098 - accuracy: 0.7773\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5073 - accuracy: 0.7725\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5070 - accuracy: 0.7844\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5006 - accuracy: 0.7820\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4975 - accuracy: 0.7796\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4987 - accuracy: 0.7773\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4975 - accuracy: 0.7773\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4948 - accuracy: 0.7773\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4897 - accuracy: 0.7844\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4886 - accuracy: 0.7820\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4886 - accuracy: 0.7844\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4875 - accuracy: 0.7820\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4866 - accuracy: 0.7891\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4895 - accuracy: 0.7796\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4792 - accuracy: 0.7820\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4787 - accuracy: 0.7867\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4744 - accuracy: 0.7867\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4731 - accuracy: 0.7844\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4709 - accuracy: 0.7867\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4718 - accuracy: 0.7891\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4687 - accuracy: 0.7938\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4732 - accuracy: 0.7891\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4743 - accuracy: 0.7915\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4687 - accuracy: 0.7867\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4643 - accuracy: 0.7962\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4593 - accuracy: 0.7962\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4581 - accuracy: 0.8033\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4589 - accuracy: 0.8009\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4586 - accuracy: 0.8081\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4534 - accuracy: 0.8033\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4557 - accuracy: 0.8128\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4517 - accuracy: 0.8057\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4541 - accuracy: 0.8033\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4459 - accuracy: 0.7986\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4524 - accuracy: 0.8081\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4397 - accuracy: 0.8104\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4420 - accuracy: 0.8152\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4567 - accuracy: 0.8104\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4402 - accuracy: 0.8199\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4397 - accuracy: 0.8057\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4287 - accuracy: 0.8223\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4357 - accuracy: 0.8081\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4284 - accuracy: 0.8199\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4204 - accuracy: 0.8175\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4233 - accuracy: 0.8246\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4226 - accuracy: 0.8223\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4185 - accuracy: 0.8246\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4194 - accuracy: 0.8341\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4137 - accuracy: 0.8318\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4133 - accuracy: 0.8270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bea049860>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5472 - accuracy: 0.7163\n",
      "Normal Neural Network 1d - Loss: 0.6274816939171325, Accuracy: 0.716312050819397\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1d - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 1d results\n",
    "\n",
    "Model: \"sequential_3\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_9 (Dense)              (None, 100)               1100      \n",
    "_________________________________________________________________\n",
    "dense_10 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_11 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,402\n",
    "Trainable params: 11,402\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 0.5523 - accuracy: 0.7092\n",
    "Normal Neural Network 1d - Loss: 0.6431249925430785, Accuracy: 0.7092198729515076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a: take out Loan_Amount_Term column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 9) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'LogTotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=9))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,302\n",
      "Trainable params: 11,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6243 - accuracy: 0.6493\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5652 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5452 - accuracy: 0.7227\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5325 - accuracy: 0.7701\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5263 - accuracy: 0.7867\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5281 - accuracy: 0.7678\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5194 - accuracy: 0.7749\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5142 - accuracy: 0.7749\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5114 - accuracy: 0.7678\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5139 - accuracy: 0.7678\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5097 - accuracy: 0.7796\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5053 - accuracy: 0.7773\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5050 - accuracy: 0.7701\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5010 - accuracy: 0.7773\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5012 - accuracy: 0.7773\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4982 - accuracy: 0.7773\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4981 - accuracy: 0.7749\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4922 - accuracy: 0.7773\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4874 - accuracy: 0.7773\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4867 - accuracy: 0.7844\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4836 - accuracy: 0.7820\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4813 - accuracy: 0.7820\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4768 - accuracy: 0.7844\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4789 - accuracy: 0.7820\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4738 - accuracy: 0.7844\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4704 - accuracy: 0.7867\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4678 - accuracy: 0.7915\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4641 - accuracy: 0.7891\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4665 - accuracy: 0.7962\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4649 - accuracy: 0.8104\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4577 - accuracy: 0.8033\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4546 - accuracy: 0.8081\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4576 - accuracy: 0.7986\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4546 - accuracy: 0.8223\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4495 - accuracy: 0.8199\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4428 - accuracy: 0.8199\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4402 - accuracy: 0.8128\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4364 - accuracy: 0.8175\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4357 - accuracy: 0.8128\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4332 - accuracy: 0.8175\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4352 - accuracy: 0.8104\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4286 - accuracy: 0.8294\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4259 - accuracy: 0.8223\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4230 - accuracy: 0.8223\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4229 - accuracy: 0.8175\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4197 - accuracy: 0.8223\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4166 - accuracy: 0.8246\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4159 - accuracy: 0.8294\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4133 - accuracy: 0.8270\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4103 - accuracy: 0.8341\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4064 - accuracy: 0.8318\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4067 - accuracy: 0.8318\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4157 - accuracy: 0.8223\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4016 - accuracy: 0.8341\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4024 - accuracy: 0.8341\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.3997 - accuracy: 0.8365\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3954 - accuracy: 0.8389\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3999 - accuracy: 0.8341\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4020 - accuracy: 0.8341\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3918 - accuracy: 0.8270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bf8e0ee10>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5261 - accuracy: 0.6950\n",
      "Normal Neural Network 2a - Loss: 0.6599454976988177, Accuracy: 0.695035457611084\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 2a - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 2a results\n",
    "_________________________________________________________________\n",
    "Model: \"sequential_4\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_12 (Dense)             (None, 100)               1000      \n",
    "_________________________________________________________________\n",
    "dense_13 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_14 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,302\n",
    "Trainable params: 11,302\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.5610 - accuracy: 0.6950\n",
    "Normal Neural Network 2a - Loss: 0.6652026197589036, Accuracy: 0.695035457611084\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b: Separate income, take out Loan_Amount_Term column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 10) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'Loan_Amount_Term', \"TotalIncome\", \"LogLoanAmount\", 'LogTotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=10))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,402\n",
      "Trainable params: 11,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6123 - accuracy: 0.6967\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5638 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5405 - accuracy: 0.7180\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5278 - accuracy: 0.7725\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5221 - accuracy: 0.7678\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5165 - accuracy: 0.7678\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5166 - accuracy: 0.7678\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5139 - accuracy: 0.7773\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5097 - accuracy: 0.7773\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5106 - accuracy: 0.7725\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5101 - accuracy: 0.7796\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5005 - accuracy: 0.7725\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5016 - accuracy: 0.7749\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4983 - accuracy: 0.7773\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4963 - accuracy: 0.7773\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.5029 - accuracy: 0.7820\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.5062 - accuracy: 0.7796\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4912 - accuracy: 0.7773\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4874 - accuracy: 0.7820\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4824 - accuracy: 0.7844\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4800 - accuracy: 0.7867\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4804 - accuracy: 0.7891\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4776 - accuracy: 0.7867\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4720 - accuracy: 0.7891\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4727 - accuracy: 0.7867\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4708 - accuracy: 0.7915\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4641 - accuracy: 0.7962\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4621 - accuracy: 0.7938\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4604 - accuracy: 0.7938\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4560 - accuracy: 0.8057\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4553 - accuracy: 0.8057\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4492 - accuracy: 0.8033\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4463 - accuracy: 0.8009\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4451 - accuracy: 0.8081\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4424 - accuracy: 0.8081\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4403 - accuracy: 0.8081\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4390 - accuracy: 0.8081\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4346 - accuracy: 0.8104\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4356 - accuracy: 0.8152\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4402 - accuracy: 0.8199\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4264 - accuracy: 0.8270\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4355 - accuracy: 0.8175\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4206 - accuracy: 0.8294\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4194 - accuracy: 0.8365\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4158 - accuracy: 0.8341\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4132 - accuracy: 0.8412\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4106 - accuracy: 0.8389\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4149 - accuracy: 0.8294\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4071 - accuracy: 0.8318\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4079 - accuracy: 0.8389\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4069 - accuracy: 0.8436\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4024 - accuracy: 0.8318\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4013 - accuracy: 0.8412\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4009 - accuracy: 0.8341\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.3928 - accuracy: 0.8412\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.3927 - accuracy: 0.8389\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3880 - accuracy: 0.8460\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3902 - accuracy: 0.8483\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3865 - accuracy: 0.8483\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3931 - accuracy: 0.8389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bf8f7f4e0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.6408 - accuracy: 0.6879\n",
      "Normal Neural Network 2b - Loss: 0.7477878869002592, Accuracy: 0.6879432797431946\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 2b - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 2b Results\n",
    "\n",
    "Model: \"sequential_5\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_15 (Dense)             (None, 100)               1100      \n",
    "_________________________________________________________________\n",
    "dense_16 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_17 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,402\n",
    "Trainable params: 11,402\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 0.7053 - accuracy: 0.6738\n",
    "Normal Neural Network 2b - Loss: 0.7237191187574509, Accuracy: 0.673758864402771"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c: take out Loan_Amount_Term column, use log(TotalIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 9) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'TotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=9))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,302\n",
      "Trainable params: 11,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6070 - accuracy: 0.6991\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5751 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5491 - accuracy: 0.7038\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5360 - accuracy: 0.7417\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5242 - accuracy: 0.7654\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5198 - accuracy: 0.7749\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5161 - accuracy: 0.7701\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5125 - accuracy: 0.7773\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5121 - accuracy: 0.7773\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5056 - accuracy: 0.7773\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5035 - accuracy: 0.7749\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5040 - accuracy: 0.7749\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.4997 - accuracy: 0.7773\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4989 - accuracy: 0.7773\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5029 - accuracy: 0.7725\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.5110 - accuracy: 0.7749\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4957 - accuracy: 0.7749\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4982 - accuracy: 0.7796\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4913 - accuracy: 0.7773\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4896 - accuracy: 0.7796\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4853 - accuracy: 0.7844\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4846 - accuracy: 0.7796\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4881 - accuracy: 0.7915\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4774 - accuracy: 0.7796\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4801 - accuracy: 0.7844\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4741 - accuracy: 0.7938\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4712 - accuracy: 0.7915\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4679 - accuracy: 0.7915\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4656 - accuracy: 0.7986\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4639 - accuracy: 0.7962\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4686 - accuracy: 0.7867\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4642 - accuracy: 0.7915\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4571 - accuracy: 0.7915\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4610 - accuracy: 0.8057\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4578 - accuracy: 0.8009\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4531 - accuracy: 0.8057\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4494 - accuracy: 0.8128\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4496 - accuracy: 0.8175\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4464 - accuracy: 0.8081\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4456 - accuracy: 0.8128\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4421 - accuracy: 0.8199\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4370 - accuracy: 0.8033\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4389 - accuracy: 0.8104\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4336 - accuracy: 0.8246\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4340 - accuracy: 0.8199\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4300 - accuracy: 0.8152\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4270 - accuracy: 0.8175\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4272 - accuracy: 0.8223\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4300 - accuracy: 0.8246\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4228 - accuracy: 0.8246\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4217 - accuracy: 0.8128\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4166 - accuracy: 0.8294\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4173 - accuracy: 0.8270\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4132 - accuracy: 0.8294\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4172 - accuracy: 0.8294\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4134 - accuracy: 0.8294\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4140 - accuracy: 0.8318\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4083 - accuracy: 0.8294\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4044 - accuracy: 0.8318\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4077 - accuracy: 0.8294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bea2ec9e8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5430 - accuracy: 0.6950\n",
      "Normal Neural Network 2c - Loss: 0.660601813319727, Accuracy: 0.695035457611084\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 2c - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 2c results\n",
    "\n",
    "Model: \"sequential_6\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_18 (Dense)             (None, 100)               1000      \n",
    "_________________________________________________________________\n",
    "dense_19 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_20 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,302\n",
    "Trainable params: 11,302\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 0.6211 - accuracy: 0.7163\n",
    "Normal Neural Network 2c - Loss: 0.6821013312813238, Accuracy: 0.716312050819397"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2d: take out Loan_Amount_Term column, use log(TotalIncome), log(LoanAmount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 9) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\", \"LoanAmount\", 'TotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=9))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,302\n",
      "Trainable params: 11,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6100 - accuracy: 0.6588\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5685 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5500 - accuracy: 0.7133\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5332 - accuracy: 0.7370\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5233 - accuracy: 0.7773\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5204 - accuracy: 0.7678\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5180 - accuracy: 0.7749\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5097 - accuracy: 0.7773\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5078 - accuracy: 0.7701\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5020 - accuracy: 0.7678\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5072 - accuracy: 0.7725\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5016 - accuracy: 0.7844\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.4976 - accuracy: 0.7773\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4959 - accuracy: 0.7796\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4939 - accuracy: 0.7773\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4954 - accuracy: 0.7867\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4883 - accuracy: 0.7820\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4910 - accuracy: 0.7820\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4854 - accuracy: 0.7796\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4837 - accuracy: 0.7844\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4801 - accuracy: 0.7867\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4810 - accuracy: 0.7844\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4869 - accuracy: 0.7891\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4823 - accuracy: 0.7915\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4733 - accuracy: 0.7938\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4755 - accuracy: 0.8057\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4687 - accuracy: 0.7938\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4658 - accuracy: 0.7938\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4661 - accuracy: 0.7938\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4633 - accuracy: 0.7867\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4597 - accuracy: 0.7938\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4618 - accuracy: 0.8009\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4601 - accuracy: 0.7915\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4510 - accuracy: 0.8009\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4520 - accuracy: 0.7986\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4481 - accuracy: 0.8009\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4462 - accuracy: 0.7986\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4479 - accuracy: 0.8009\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4445 - accuracy: 0.8057\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4411 - accuracy: 0.8057\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4488 - accuracy: 0.8128\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4391 - accuracy: 0.8081\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4343 - accuracy: 0.8152\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4320 - accuracy: 0.8175\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4288 - accuracy: 0.8128\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4302 - accuracy: 0.8175\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4261 - accuracy: 0.8223\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4210 - accuracy: 0.8199\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4204 - accuracy: 0.8270\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4213 - accuracy: 0.8246\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4326 - accuracy: 0.8294\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4196 - accuracy: 0.8365\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4156 - accuracy: 0.8365\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4125 - accuracy: 0.8341\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4102 - accuracy: 0.8318\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4093 - accuracy: 0.8318\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4041 - accuracy: 0.8318\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4032 - accuracy: 0.8389\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4033 - accuracy: 0.8365\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4037 - accuracy: 0.8341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bd0c07c88>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5993 - accuracy: 0.6879\n",
      "Normal Neural Network 2d - Loss: 0.6693894389673327, Accuracy: 0.6879432797431946\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 2d - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 2d results\n",
    "\n",
    "Model: \"sequential_7\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_21 (Dense)             (None, 100)               1000      \n",
    "_________________________________________________________________\n",
    "dense_22 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_23 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,302\n",
    "Trainable params: 11,302\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 0.6568 - accuracy: 0.6809\n",
    "Normal Neural Network 2d - Loss: 0.7042758709995459, Accuracy: 0.6808510422706604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a: take out Loan_Amount_Term and LoanAmount columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 8) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'LogTotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=8))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 100)               900       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,202\n",
      "Trainable params: 11,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6074 - accuracy: 0.6991\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5659 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5459 - accuracy: 0.7393\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5350 - accuracy: 0.7536\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5286 - accuracy: 0.7607\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5211 - accuracy: 0.7844\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5200 - accuracy: 0.7749\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5157 - accuracy: 0.7796\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5130 - accuracy: 0.7725\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5096 - accuracy: 0.7749\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5078 - accuracy: 0.7749\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5057 - accuracy: 0.7773\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5047 - accuracy: 0.7773\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5042 - accuracy: 0.7701\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5009 - accuracy: 0.7820\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.5073 - accuracy: 0.7749\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4969 - accuracy: 0.7796\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4958 - accuracy: 0.7796\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4941 - accuracy: 0.7844\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4923 - accuracy: 0.7796\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4879 - accuracy: 0.7773\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4865 - accuracy: 0.7820\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4917 - accuracy: 0.7844\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4903 - accuracy: 0.7773\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4860 - accuracy: 0.7962\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4792 - accuracy: 0.7844\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4779 - accuracy: 0.7867\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4750 - accuracy: 0.7820\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4737 - accuracy: 0.7867\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4734 - accuracy: 0.7867\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4680 - accuracy: 0.7962\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4684 - accuracy: 0.7867\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4645 - accuracy: 0.8009\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4749 - accuracy: 0.8033\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4631 - accuracy: 0.7773\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4591 - accuracy: 0.8033\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4559 - accuracy: 0.8033\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4560 - accuracy: 0.8033\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4516 - accuracy: 0.7962\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4532 - accuracy: 0.8081\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4497 - accuracy: 0.8081\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4503 - accuracy: 0.7962\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4468 - accuracy: 0.8128\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4466 - accuracy: 0.8057\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4386 - accuracy: 0.8152\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4424 - accuracy: 0.8128\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4500 - accuracy: 0.8104\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4395 - accuracy: 0.8128\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4508 - accuracy: 0.7962\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4450 - accuracy: 0.8104\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4289 - accuracy: 0.8128\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4294 - accuracy: 0.8081\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4246 - accuracy: 0.8223\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4250 - accuracy: 0.8152\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4233 - accuracy: 0.8223\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4220 - accuracy: 0.8175\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4236 - accuracy: 0.8223\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4205 - accuracy: 0.8246\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4199 - accuracy: 0.8223\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4211 - accuracy: 0.8246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bea619828>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5901 - accuracy: 0.7092\n",
      "Normal Neural Network 3a - Loss: 0.6524173710363131, Accuracy: 0.7092198729515076\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 3a - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 3a results\n",
    "_________________________________________________________________\n",
    "Model: \"sequential_8\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_24 (Dense)             (None, 100)               900       \n",
    "_________________________________________________________________\n",
    "dense_25 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_26 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,202\n",
    "Trainable params: 11,202\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.5328 - accuracy: 0.6879\n",
    "Normal Neural Network 3a - Loss: 0.6187358534505182, Accuracy: 0.6879432797431946"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b: Separate income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 9) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"TotalIncome\", \"LogLoanAmount\", 'LogTotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=9))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,302\n",
      "Trainable params: 11,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.5857 - accuracy: 0.7062\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5565 - accuracy: 0.7085\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5396 - accuracy: 0.7417\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5277 - accuracy: 0.7725\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5209 - accuracy: 0.7678\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5165 - accuracy: 0.7773\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5170 - accuracy: 0.7749\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5133 - accuracy: 0.7773\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5156 - accuracy: 0.7749\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5101 - accuracy: 0.7773\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5102 - accuracy: 0.7773\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5049 - accuracy: 0.7773\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5037 - accuracy: 0.7773\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5015 - accuracy: 0.7773\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4961 - accuracy: 0.7773\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4955 - accuracy: 0.7773\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4924 - accuracy: 0.7773\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4933 - accuracy: 0.7773\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4928 - accuracy: 0.7773\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4874 - accuracy: 0.7773\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4988 - accuracy: 0.7773\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4834 - accuracy: 0.7773\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4861 - accuracy: 0.7796\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4820 - accuracy: 0.7796\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4796 - accuracy: 0.7844\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4764 - accuracy: 0.7820\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4808 - accuracy: 0.7844\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4720 - accuracy: 0.7867\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4674 - accuracy: 0.7891\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4659 - accuracy: 0.7938\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4623 - accuracy: 0.7962\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4641 - accuracy: 0.7986\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4632 - accuracy: 0.8033\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4573 - accuracy: 0.8081\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4533 - accuracy: 0.8033\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4507 - accuracy: 0.7962\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4517 - accuracy: 0.8081\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4465 - accuracy: 0.8057\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4433 - accuracy: 0.8081\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4404 - accuracy: 0.8081\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4387 - accuracy: 0.8152\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4373 - accuracy: 0.8104\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4337 - accuracy: 0.8081\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4342 - accuracy: 0.8033\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4275 - accuracy: 0.8152\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4262 - accuracy: 0.8175\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4205 - accuracy: 0.8246\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4271 - accuracy: 0.8057\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4181 - accuracy: 0.8175\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4207 - accuracy: 0.8270\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4170 - accuracy: 0.8270\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4114 - accuracy: 0.8246\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4122 - accuracy: 0.8223\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4178 - accuracy: 0.8223\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4106 - accuracy: 0.8318\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4041 - accuracy: 0.8294\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3995 - accuracy: 0.8294\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4000 - accuracy: 0.8365\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3972 - accuracy: 0.8341\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3953 - accuracy: 0.8270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bc92df748>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 1s - loss: 0.6967 - accuracy: 0.6596\n",
      "Normal Neural Network 3b - Loss: 0.7645552128764754, Accuracy: 0.6595744490623474\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 3b - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 3b results\n",
    "\n",
    "Model: \"sequential_9\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_27 (Dense)             (None, 100)               1000      \n",
    "_________________________________________________________________\n",
    "dense_28 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_29 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,302\n",
    "Trainable params: 11,302\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 1s - loss: 0.6357 - accuracy: 0.6596\n",
    "Normal Neural Network 3b - Loss: 0.6898306582836394, Accuracy: 0.6595744490623474"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c: take out Loan_Amount_Term and LoanAmount columns, use log(TotalIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 8) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'TotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=8))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 100)               900       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,202\n",
      "Trainable params: 11,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6173 - accuracy: 0.6848\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5685 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5523 - accuracy: 0.7180\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5432 - accuracy: 0.7370\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5330 - accuracy: 0.7393\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5245 - accuracy: 0.7749\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5248 - accuracy: 0.7678\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5238 - accuracy: 0.7749\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5142 - accuracy: 0.7678\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5183 - accuracy: 0.7678\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5165 - accuracy: 0.7725\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5074 - accuracy: 0.7678\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5043 - accuracy: 0.7725\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5112 - accuracy: 0.7678\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5143 - accuracy: 0.7796\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.5007 - accuracy: 0.7820\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4949 - accuracy: 0.7820\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4987 - accuracy: 0.7844\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.5031 - accuracy: 0.7773\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4914 - accuracy: 0.7773\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4895 - accuracy: 0.7844\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4876 - accuracy: 0.7844\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4850 - accuracy: 0.7844\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4836 - accuracy: 0.7844\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4796 - accuracy: 0.7891\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4785 - accuracy: 0.7867\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4870 - accuracy: 0.7891\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4770 - accuracy: 0.7938\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4733 - accuracy: 0.7844\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4776 - accuracy: 0.7844\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4765 - accuracy: 0.8009\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4773 - accuracy: 0.7820\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4686 - accuracy: 0.7938\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4639 - accuracy: 0.7915\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4613 - accuracy: 0.7938\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4591 - accuracy: 0.7962\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4641 - accuracy: 0.7891\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4570 - accuracy: 0.7915\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4627 - accuracy: 0.8009\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4539 - accuracy: 0.8057\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4473 - accuracy: 0.8033\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4458 - accuracy: 0.7986\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4456 - accuracy: 0.8081\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4438 - accuracy: 0.7962\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4408 - accuracy: 0.8104\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4385 - accuracy: 0.8175\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4390 - accuracy: 0.8175\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4404 - accuracy: 0.8152\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4302 - accuracy: 0.8246\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4310 - accuracy: 0.8246\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4282 - accuracy: 0.8318\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4308 - accuracy: 0.8152\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4244 - accuracy: 0.8270\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4220 - accuracy: 0.8318\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4250 - accuracy: 0.8246\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4258 - accuracy: 0.8223\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4178 - accuracy: 0.8294\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4143 - accuracy: 0.8389\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4112 - accuracy: 0.8294\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4111 - accuracy: 0.8318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bd8ca79e8>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.6204 - accuracy: 0.6667\n",
      "Normal Neural Network 3c - Loss: 0.6584342181259859, Accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 3c - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 3c results\n",
    "\n",
    "Model: \"sequential_10\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_30 (Dense)             (None, 100)               900       \n",
    "_________________________________________________________________\n",
    "dense_31 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_32 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,202\n",
    "Trainable params: 11,202\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 0.5261 - accuracy: 0.7234\n",
    "Normal Neural Network 3c - Loss: 0.651864561628788, Accuracy: 0.7234042286872864  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4a take out Loan_Amount_Term and LoanAmount columns, add a layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 8) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'LogTotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=8))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 100)               900       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 21,302\n",
      "Trainable params: 21,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6166 - accuracy: 0.6588\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5575 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5458 - accuracy: 0.7701\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5283 - accuracy: 0.7678\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5193 - accuracy: 0.7678\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5158 - accuracy: 0.7701\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5116 - accuracy: 0.7749\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5100 - accuracy: 0.7749\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5037 - accuracy: 0.7749\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5059 - accuracy: 0.7749\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5015 - accuracy: 0.7915\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.4971 - accuracy: 0.7844\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.4941 - accuracy: 0.7867\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4908 - accuracy: 0.7796\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4867 - accuracy: 0.7867\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4798 - accuracy: 0.7962\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4825 - accuracy: 0.7867\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4781 - accuracy: 0.7844\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4688 - accuracy: 0.7891\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4663 - accuracy: 0.7915\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4642 - accuracy: 0.8009\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4605 - accuracy: 0.7891\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4590 - accuracy: 0.7986\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4776 - accuracy: 0.8009\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4596 - accuracy: 0.8057\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4495 - accuracy: 0.8081\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4571 - accuracy: 0.8009\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4454 - accuracy: 0.8081\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4381 - accuracy: 0.8199\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4362 - accuracy: 0.8104\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4302 - accuracy: 0.8246\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4391 - accuracy: 0.8033\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4238 - accuracy: 0.8104\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4200 - accuracy: 0.8152\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4161 - accuracy: 0.8223\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4226 - accuracy: 0.8223\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4136 - accuracy: 0.8246\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4085 - accuracy: 0.8341\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4055 - accuracy: 0.8270\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4040 - accuracy: 0.8318\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4095 - accuracy: 0.8365\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4218 - accuracy: 0.8104\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.3999 - accuracy: 0.8341\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.3947 - accuracy: 0.8483\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.3865 - accuracy: 0.8389\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.3905 - accuracy: 0.8412\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.3849 - accuracy: 0.8412\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.3871 - accuracy: 0.8389\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.3857 - accuracy: 0.8412\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.3867 - accuracy: 0.8365\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.3870 - accuracy: 0.8436\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.3853 - accuracy: 0.8341\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.3729 - accuracy: 0.8436\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.3700 - accuracy: 0.8460\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.3634 - accuracy: 0.8483\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.3631 - accuracy: 0.8460\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3590 - accuracy: 0.8507\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3625 - accuracy: 0.8365\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3669 - accuracy: 0.8436\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3622 - accuracy: 0.8507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bba1eccf8>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 1.0925 - accuracy: 0.6738\n",
      "Normal Neural Network 4a - Loss: 1.0454478035581873, Accuracy: 0.673758864402771\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 4a - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 4a results\n",
    "\n",
    "Model: \"sequential_11\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_33 (Dense)             (None, 100)               900       \n",
    "_________________________________________________________________\n",
    "dense_34 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_35 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_36 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 21,302\n",
    "Trainable params: 21,302\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.9865 - accuracy: 0.6667\n",
    "Normal Neural Network 4a - Loss: 1.0510162102415206, Accuracy: 0.6666666865348816\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b: Separate income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 9) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"TotalIncome\", \"LogLoanAmount\", 'LogTotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=9))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 21,402\n",
      "Trainable params: 21,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6164 - accuracy: 0.7014\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5719 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5465 - accuracy: 0.7014\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5357 - accuracy: 0.7512\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5226 - accuracy: 0.7773\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5175 - accuracy: 0.7749\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5202 - accuracy: 0.7749\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5183 - accuracy: 0.7749\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5129 - accuracy: 0.7773\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5138 - accuracy: 0.7749\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5071 - accuracy: 0.7773\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.4994 - accuracy: 0.7773\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.4957 - accuracy: 0.7773\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4894 - accuracy: 0.7773\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4871 - accuracy: 0.7773\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4838 - accuracy: 0.7820\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4792 - accuracy: 0.7796\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4767 - accuracy: 0.7962\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4699 - accuracy: 0.7962\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4675 - accuracy: 0.8009\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4788 - accuracy: 0.7986\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4723 - accuracy: 0.7938\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4644 - accuracy: 0.7938\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4591 - accuracy: 0.8175\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4481 - accuracy: 0.8128\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4452 - accuracy: 0.8057\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4430 - accuracy: 0.8057\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4408 - accuracy: 0.8199\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4385 - accuracy: 0.8199\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4369 - accuracy: 0.8104\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4284 - accuracy: 0.8128\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4187 - accuracy: 0.8081\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4360 - accuracy: 0.8081\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4081 - accuracy: 0.8294\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4123 - accuracy: 0.8270\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4111 - accuracy: 0.8175\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.3969 - accuracy: 0.8294\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4040 - accuracy: 0.8270\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.3973 - accuracy: 0.8294\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.3932 - accuracy: 0.8341\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.3899 - accuracy: 0.8341\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.3908 - accuracy: 0.8365\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.3765 - accuracy: 0.8460\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.3818 - accuracy: 0.8389\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.3795 - accuracy: 0.8412\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.3749 - accuracy: 0.8460\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.3737 - accuracy: 0.8460\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.3643 - accuracy: 0.8436\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.3604 - accuracy: 0.8483\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.3761 - accuracy: 0.8318\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.3824 - accuracy: 0.8270\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.3619 - accuracy: 0.8389\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.3770 - accuracy: 0.8270\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.3678 - accuracy: 0.8365\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.3483 - accuracy: 0.8555\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.3676 - accuracy: 0.8483\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3664 - accuracy: 0.8578\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3427 - accuracy: 0.8531\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3489 - accuracy: 0.8483\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3728 - accuracy: 0.8507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8beaa64940>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.8273 - accuracy: 0.6809\n",
      "Normal Neural Network 4b - Loss: 0.8672996049231672, Accuracy: 0.6808510422706604\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 4b - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 4b results\n",
    "\n",
    "Model: \"sequential_12\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_37 (Dense)             (None, 100)               1000      \n",
    "_________________________________________________________________\n",
    "dense_38 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_39 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_40 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 21,402\n",
    "Trainable params: 21,402\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 0.9863 - accuracy: 0.6667\n",
    "Normal Neural Network 4b - Loss: 1.1121582591787298, Accuracy: 0.6666666865348816  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4c take out Loan_Amount_Term and LoanAmount columns, add a layer, used log(TotalIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 8) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'TotalIncome'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=8))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 100)               900       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 21,302\n",
      "Trainable params: 21,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 2s - loss: 0.6101 - accuracy: 0.7014\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5644 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5467 - accuracy: 0.7559\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5317 - accuracy: 0.7701\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5172 - accuracy: 0.7725\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5193 - accuracy: 0.7701\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5175 - accuracy: 0.7749\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5151 - accuracy: 0.7820\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5029 - accuracy: 0.7867\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5001 - accuracy: 0.7773\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.4963 - accuracy: 0.7867\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.4883 - accuracy: 0.7867\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.4855 - accuracy: 0.7820\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4806 - accuracy: 0.7844\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4760 - accuracy: 0.7938\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4728 - accuracy: 0.7844\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4716 - accuracy: 0.7986\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4663 - accuracy: 0.7986\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4609 - accuracy: 0.8057\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4568 - accuracy: 0.8104\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4553 - accuracy: 0.8057\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4478 - accuracy: 0.8081\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4484 - accuracy: 0.8152\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4447 - accuracy: 0.8009\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4411 - accuracy: 0.8152\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4422 - accuracy: 0.8175\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4332 - accuracy: 0.8128\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4348 - accuracy: 0.8128\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4249 - accuracy: 0.8223\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4256 - accuracy: 0.8199\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4286 - accuracy: 0.8199\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4239 - accuracy: 0.8294\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4135 - accuracy: 0.8270\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4069 - accuracy: 0.8341\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4126 - accuracy: 0.8270\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4195 - accuracy: 0.8246\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4151 - accuracy: 0.8199\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4000 - accuracy: 0.8412\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.3885 - accuracy: 0.8483\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.3990 - accuracy: 0.8507\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4018 - accuracy: 0.8389\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.3921 - accuracy: 0.8389\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4046 - accuracy: 0.8270\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.3973 - accuracy: 0.8318\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.3996 - accuracy: 0.8318\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.3828 - accuracy: 0.8389\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.3786 - accuracy: 0.8436\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.3744 - accuracy: 0.8507\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.3737 - accuracy: 0.8460\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.3661 - accuracy: 0.8507\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.3577 - accuracy: 0.8602\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.3611 - accuracy: 0.8578\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.3584 - accuracy: 0.8555\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.3734 - accuracy: 0.8507\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.3655 - accuracy: 0.8555\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.3528 - accuracy: 0.8578\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3524 - accuracy: 0.8626\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3642 - accuracy: 0.8626\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3474 - accuracy: 0.8649\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3487 - accuracy: 0.8436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bd8f874a8>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 1.0077 - accuracy: 0.6667\n",
      "Normal Neural Network 4c - Loss: 1.0052797371614064, Accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 4c - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 4c results\n",
    "\n",
    "Model: \"sequential_13\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_41 (Dense)             (None, 100)               900       \n",
    "_________________________________________________________________\n",
    "dense_42 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_43 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_44 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 21,302\n",
    "Trainable params: 21,302\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 1.2298 - accuracy: 0.6667\n",
    "Normal Neural Network 4c - Loss: 1.0912111718603905, Accuracy: 0.6666666865348816"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a: 2 layers, Total Income, take out Loan_Amount_Term and LoanAmount columns, also remove columns with lower importance in Random Tree runs ( 'Gender', 'Education', 'Self_Employed', 'Married')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 4) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'LogTotalIncome', 'Gender', 'Education', 'Self_Employed', 'Married'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=4))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 100)               500       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6180 - accuracy: 0.6848\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5553 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5515 - accuracy: 0.7062\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5399 - accuracy: 0.7370\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5342 - accuracy: 0.7512\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5312 - accuracy: 0.7630\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5313 - accuracy: 0.7678\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5312 - accuracy: 0.7678\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5248 - accuracy: 0.7678\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5289 - accuracy: 0.7678\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5239 - accuracy: 0.7678\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5266 - accuracy: 0.7678\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5263 - accuracy: 0.7678\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5231 - accuracy: 0.7678\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5225 - accuracy: 0.7678\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.5223 - accuracy: 0.7678\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.5202 - accuracy: 0.7678\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.5205 - accuracy: 0.7678\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.5232 - accuracy: 0.7678\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.5222 - accuracy: 0.7678\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.5177 - accuracy: 0.7678\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.5230 - accuracy: 0.7678\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.5190 - accuracy: 0.7678\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.5219 - accuracy: 0.7678\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.5198 - accuracy: 0.7678\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.5173 - accuracy: 0.7678\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.5186 - accuracy: 0.7678\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.5210 - accuracy: 0.7678\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.5178 - accuracy: 0.7678\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.5180 - accuracy: 0.7678\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.5150 - accuracy: 0.7678\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.5163 - accuracy: 0.7678\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.5172 - accuracy: 0.7678\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.5166 - accuracy: 0.7678\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.5188 - accuracy: 0.7678\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.5151 - accuracy: 0.7678\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.5171 - accuracy: 0.7678\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.5156 - accuracy: 0.7678\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.5168 - accuracy: 0.7678\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.5203 - accuracy: 0.7678\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.5152 - accuracy: 0.7678\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.5156 - accuracy: 0.7678\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.5176 - accuracy: 0.7678\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.5135 - accuracy: 0.7678\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.5161 - accuracy: 0.7701\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.5117 - accuracy: 0.7678\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.5164 - accuracy: 0.7678\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.5127 - accuracy: 0.7678\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.5161 - accuracy: 0.7701\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.5119 - accuracy: 0.7678\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.5123 - accuracy: 0.7678\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.5119 - accuracy: 0.7678\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.5124 - accuracy: 0.7678\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.5154 - accuracy: 0.7701\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.5144 - accuracy: 0.7678\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.5138 - accuracy: 0.7678\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.5112 - accuracy: 0.7701\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.5146 - accuracy: 0.7701\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.5110 - accuracy: 0.7701\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.5105 - accuracy: 0.7701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bd0822668>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.4831 - accuracy: 0.7518\n",
      "Normal Neural Network 5a - Loss: 0.5475983116643649, Accuracy: 0.7517730593681335\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 5a - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 5a results\n",
    "Model: \"sequential_15\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_48 (Dense)             (None, 100)               500       \n",
    "_________________________________________________________________\n",
    "dense_49 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_50 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 10,802\n",
    "Trainable params: 10,802\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.4831 - accuracy: 0.7518\n",
    "Normal Neural Network 5a - Loss: 0.5475983116643649, Accuracy: 0.7517730593681335\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5b: 2 layers, App, Co-App, take out Loan_Amount_Term and LoanAmount columns, also remove columns with lower importance in Random Tree runs ( 'Gender', 'Education', 'Self_Employed', 'Married')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 5) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"TotalIncome\", \"LogLoanAmount\", 'LogTotalIncome', 'Gender', 'Education', 'Self_Employed', 'Married'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 100)               600       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 10,902\n",
      "Trainable params: 10,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6010 - accuracy: 0.6967\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5539 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5391 - accuracy: 0.7393\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5343 - accuracy: 0.7678\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5279 - accuracy: 0.7678\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5258 - accuracy: 0.7678\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5249 - accuracy: 0.7678\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5224 - accuracy: 0.7678\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5267 - accuracy: 0.7678\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5206 - accuracy: 0.7678\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5212 - accuracy: 0.7678\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5192 - accuracy: 0.7678\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5183 - accuracy: 0.7678\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5189 - accuracy: 0.7678\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5178 - accuracy: 0.7678\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.5176 - accuracy: 0.7678\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.5180 - accuracy: 0.7678\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.5143 - accuracy: 0.7678\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.5152 - accuracy: 0.7678\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.5123 - accuracy: 0.7678\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.5133 - accuracy: 0.7678\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.5137 - accuracy: 0.7678\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.5118 - accuracy: 0.7678\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.5121 - accuracy: 0.7678\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.5094 - accuracy: 0.7678\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.5092 - accuracy: 0.7678\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.5096 - accuracy: 0.7701\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.5126 - accuracy: 0.7749\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.5101 - accuracy: 0.7725\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.5090 - accuracy: 0.7725\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.5089 - accuracy: 0.7725\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.5077 - accuracy: 0.7725\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.5095 - accuracy: 0.7725\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.5045 - accuracy: 0.7725\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.5065 - accuracy: 0.7725\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.5102 - accuracy: 0.7773\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.5054 - accuracy: 0.7749\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.5052 - accuracy: 0.7773\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.5043 - accuracy: 0.7749\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.5024 - accuracy: 0.7749\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.5025 - accuracy: 0.7773\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.5038 - accuracy: 0.7725\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.5004 - accuracy: 0.7749\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.5044 - accuracy: 0.7749\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.5006 - accuracy: 0.7820\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.5013 - accuracy: 0.7749\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.5055 - accuracy: 0.7773\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.5082 - accuracy: 0.7796\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.5027 - accuracy: 0.7820\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4991 - accuracy: 0.7820\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4978 - accuracy: 0.7796\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4953 - accuracy: 0.7796\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4947 - accuracy: 0.7820\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4951 - accuracy: 0.7820\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.5025 - accuracy: 0.7844\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4954 - accuracy: 0.7796\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4958 - accuracy: 0.7820\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4953 - accuracy: 0.7820\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4951 - accuracy: 0.7844\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4923 - accuracy: 0.7796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bf95e1320>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5026 - accuracy: 0.7730\n",
      "Normal Neural Network 5b - Loss: 0.5635992305498596, Accuracy: 0.7730496525764465\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 5b - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 5b results\n",
    "\n",
    "Model: \"sequential_16\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_51 (Dense)             (None, 100)               600       \n",
    "_________________________________________________________________\n",
    "dense_52 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_53 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 10,902\n",
    "Trainable params: 10,902\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.5026 - accuracy: 0.7730\n",
    "Normal Neural Network 5b - Loss: 0.5635992305498596, Accuracy: 0.7730496525764465"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5c: 2 layers, log(Total Income), take out Loan_Amount_Term and LoanAmount columns, also remove columns with lower importance in Random Tree runs ( 'Gender', 'Education', 'Self_Employed', 'Married')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 4) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'TotalIncome', 'Gender', 'Education', 'Self_Employed', 'Married'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=4))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 100)               500       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 10,802\n",
      "Trainable params: 10,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6545 - accuracy: 0.6374\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5757 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5499 - accuracy: 0.7133\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5402 - accuracy: 0.7536\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5324 - accuracy: 0.7678\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5304 - accuracy: 0.7678\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5283 - accuracy: 0.7678\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5275 - accuracy: 0.7678\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5276 - accuracy: 0.7678\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5241 - accuracy: 0.7678\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5249 - accuracy: 0.7678\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5244 - accuracy: 0.7678\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5237 - accuracy: 0.7678\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5244 - accuracy: 0.7678\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5237 - accuracy: 0.7678\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.5205 - accuracy: 0.7678\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.5233 - accuracy: 0.7678\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.5262 - accuracy: 0.7678\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.5248 - accuracy: 0.7678\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.5217 - accuracy: 0.7678\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.5194 - accuracy: 0.7678\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.5196 - accuracy: 0.7678\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.5195 - accuracy: 0.7678\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.5185 - accuracy: 0.7678\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.5184 - accuracy: 0.7678\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.5182 - accuracy: 0.7678\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.5190 - accuracy: 0.7678\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.5187 - accuracy: 0.7678\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.5174 - accuracy: 0.7678\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.5167 - accuracy: 0.7678\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.5184 - accuracy: 0.7678\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.5187 - accuracy: 0.7678\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.5206 - accuracy: 0.7678\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.5189 - accuracy: 0.7678\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.5170 - accuracy: 0.7678\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.5158 - accuracy: 0.7678\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.5159 - accuracy: 0.7678\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.5158 - accuracy: 0.7678\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.5157 - accuracy: 0.7678\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.5149 - accuracy: 0.7678\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.5141 - accuracy: 0.7678\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.5178 - accuracy: 0.7678\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.5131 - accuracy: 0.7678\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.5167 - accuracy: 0.7678\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.5141 - accuracy: 0.7678\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.5136 - accuracy: 0.7678\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.5133 - accuracy: 0.7678\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.5123 - accuracy: 0.7678\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.5139 - accuracy: 0.7678\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.5134 - accuracy: 0.7678\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.5116 - accuracy: 0.7678\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.5136 - accuracy: 0.7678\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.5121 - accuracy: 0.7678\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.5170 - accuracy: 0.7678\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.5127 - accuracy: 0.7678\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.5097 - accuracy: 0.7678\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.5105 - accuracy: 0.7701\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.5100 - accuracy: 0.7678\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.5086 - accuracy: 0.7678\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.5084 - accuracy: 0.7678\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8beadbe978>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.4681 - accuracy: 0.7589\n",
      "Normal Neural Network 5b - Loss: 0.54210065358074, Accuracy: 0.758865237236023\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 5b - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 5c results\n",
    "\n",
    "Model: \"sequential_17\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_54 (Dense)             (None, 100)               500       \n",
    "_________________________________________________________________\n",
    "dense_55 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_56 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 10,802\n",
    "Trainable params: 10,802\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.4681 - accuracy: 0.7589\n",
    "Normal Neural Network 5b - Loss: 0.54210065358074, Accuracy: 0.758865237236023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6a: 3 layers, Total Income, take out Loan_Amount_Term and LoanAmount columns, also remove columns with lower importance in Random Tree runs ( 'Gender', 'Education', 'Self_Employed', 'Married')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 4) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'LogTotalIncome', 'Gender', 'Education', 'Self_Employed', 'Married'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=4))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_57 (Dense)             (None, 100)               500       \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 20,902\n",
      "Trainable params: 20,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6049 - accuracy: 0.6896\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5563 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5502 - accuracy: 0.7536\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5340 - accuracy: 0.7678\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5324 - accuracy: 0.7678\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5288 - accuracy: 0.7678\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5249 - accuracy: 0.7678\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5228 - accuracy: 0.7678\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5232 - accuracy: 0.7678\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5212 - accuracy: 0.7678\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5341 - accuracy: 0.7678\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5244 - accuracy: 0.7678\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5259 - accuracy: 0.7678\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5223 - accuracy: 0.7678\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5199 - accuracy: 0.7678\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.5207 - accuracy: 0.7678\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.5244 - accuracy: 0.7678\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.5158 - accuracy: 0.7678\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.5183 - accuracy: 0.7678\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.5236 - accuracy: 0.7678\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.5203 - accuracy: 0.7678\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.5180 - accuracy: 0.7678\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.5153 - accuracy: 0.7678\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.5168 - accuracy: 0.7678\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.5254 - accuracy: 0.7701\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.5179 - accuracy: 0.7678\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.5141 - accuracy: 0.7678\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.5166 - accuracy: 0.7725\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.5128 - accuracy: 0.7701\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.5150 - accuracy: 0.7725\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.5158 - accuracy: 0.7701\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.5127 - accuracy: 0.7725\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.5104 - accuracy: 0.7725\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.5108 - accuracy: 0.7725\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.5134 - accuracy: 0.7725\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.5086 - accuracy: 0.7725\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.5092 - accuracy: 0.7749\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.5121 - accuracy: 0.7725\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.5134 - accuracy: 0.7725\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.5069 - accuracy: 0.7725\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.5119 - accuracy: 0.7749\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.5099 - accuracy: 0.7773\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.5069 - accuracy: 0.7749\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.5057 - accuracy: 0.7773\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.5067 - accuracy: 0.7749\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.5094 - accuracy: 0.7749\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.5114 - accuracy: 0.7701\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.5115 - accuracy: 0.7725\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.5074 - accuracy: 0.7749\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.5044 - accuracy: 0.7773\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.5046 - accuracy: 0.7773\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.5035 - accuracy: 0.7749\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4984 - accuracy: 0.7749\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4987 - accuracy: 0.7820\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4966 - accuracy: 0.7796\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.5033 - accuracy: 0.7773\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.5045 - accuracy: 0.7796\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4973 - accuracy: 0.7796\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.5006 - accuracy: 0.7749\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4998 - accuracy: 0.7938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bd168add8>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5371 - accuracy: 0.7305\n",
      "Normal Neural Network 6a - Loss: 0.5986272792021433, Accuracy: 0.7304964661598206\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 6a - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6a results\n",
    "\n",
    "Model: \"sequential_18\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_57 (Dense)             (None, 100)               500       \n",
    "_________________________________________________________________\n",
    "dense_58 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_59 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_60 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 20,902\n",
    "Trainable params: 20,902\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.5371 - accuracy: 0.7305\n",
    "Normal Neural Network 6a - Loss: 0.5986272792021433, Accuracy: 0.7304964661598206\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6b: 3 layers, App, Co-App, take out Loan_Amount_Term and LoanAmount columns, also remove columns with lower importance in Random Tree runs ( 'Gender', 'Education', 'Self_Employed', 'Married')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 5) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"TotalIncome\", \"LogLoanAmount\", 'LogTotalIncome', 'Gender', 'Education', 'Self_Employed', 'Married'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=5))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 100)               600       \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 21,002\n",
      "Trainable params: 21,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.5944 - accuracy: 0.7014\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5546 - accuracy: 0.7038\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5574 - accuracy: 0.7654\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5375 - accuracy: 0.7630\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5326 - accuracy: 0.7678\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5287 - accuracy: 0.7678\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5280 - accuracy: 0.7678\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5234 - accuracy: 0.7678\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5187 - accuracy: 0.7678\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5217 - accuracy: 0.7678\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5193 - accuracy: 0.7678\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5152 - accuracy: 0.7678\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5181 - accuracy: 0.7678\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5161 - accuracy: 0.7678\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5163 - accuracy: 0.7701\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.5145 - accuracy: 0.7678\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.5157 - accuracy: 0.7654\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.5115 - accuracy: 0.7725\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.5106 - accuracy: 0.7701\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.5106 - accuracy: 0.7701\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.5091 - accuracy: 0.7725\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.5142 - accuracy: 0.7701\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.5066 - accuracy: 0.7701\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.5087 - accuracy: 0.7701\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.5062 - accuracy: 0.7749\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.5031 - accuracy: 0.7749\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.5059 - accuracy: 0.7725\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.5007 - accuracy: 0.7749\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.5011 - accuracy: 0.7749\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.5048 - accuracy: 0.7749\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4999 - accuracy: 0.7773\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4999 - accuracy: 0.7773\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4982 - accuracy: 0.7796\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.5006 - accuracy: 0.7773\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.5037 - accuracy: 0.7796\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.5006 - accuracy: 0.7844\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4952 - accuracy: 0.7725\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4937 - accuracy: 0.7820\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4960 - accuracy: 0.7773\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4943 - accuracy: 0.7938\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4874 - accuracy: 0.7820\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4935 - accuracy: 0.7820\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4883 - accuracy: 0.7867\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4937 - accuracy: 0.7796\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4965 - accuracy: 0.7938\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4878 - accuracy: 0.7938\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4808 - accuracy: 0.7962\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4843 - accuracy: 0.7891\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4806 - accuracy: 0.8009\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4881 - accuracy: 0.7891\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4832 - accuracy: 0.7962\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4813 - accuracy: 0.7867\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4790 - accuracy: 0.7962\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4762 - accuracy: 0.7773\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4753 - accuracy: 0.7867\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4749 - accuracy: 0.7891\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4759 - accuracy: 0.7867\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4727 - accuracy: 0.7938\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4694 - accuracy: 0.7962\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4744 - accuracy: 0.7938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8c0acecf28>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5616 - accuracy: 0.7518\n",
      "Normal Neural Network 6a - Loss: 0.6191868456542915, Accuracy: 0.7517730593681335\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 6a - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6b Results\n",
    "\n",
    "Model: \"sequential_19\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_61 (Dense)             (None, 100)               600       \n",
    "_________________________________________________________________\n",
    "dense_62 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_63 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_64 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 21,002\n",
    "Trainable params: 21,002\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.5616 - accuracy: 0.7518\n",
    "Normal Neural Network 6a - Loss: 0.6191868456542915, Accuracy: 0.7517730593681335"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6c: 3 layers, log(Total Income), take out Loan_Amount_Term and LoanAmount columns, also remove columns with lower importance in Random Tree runs ( 'Gender', 'Education', 'Self_Employed', 'Married')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 4) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\", \"LogLoanAmount\", 'TotalIncome', 'Gender', 'Education', 'Self_Employed', 'Married'], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=4))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 100)               500       \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 20,902\n",
      "Trainable params: 20,902\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6491 - accuracy: 0.6043\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5687 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5420 - accuracy: 0.7417\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5310 - accuracy: 0.7678\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5330 - accuracy: 0.7678\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5297 - accuracy: 0.7678\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5253 - accuracy: 0.7678\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5258 - accuracy: 0.7678\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5224 - accuracy: 0.7678\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5217 - accuracy: 0.7678\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5247 - accuracy: 0.7701\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5219 - accuracy: 0.7678\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5196 - accuracy: 0.7678\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5194 - accuracy: 0.7678\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5191 - accuracy: 0.7678\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.5250 - accuracy: 0.7678\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.5186 - accuracy: 0.7678\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.5223 - accuracy: 0.7678\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.5160 - accuracy: 0.7678\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.5196 - accuracy: 0.7701\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.5150 - accuracy: 0.7678\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.5169 - accuracy: 0.7678\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.5176 - accuracy: 0.7678\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.5177 - accuracy: 0.7678\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.5254 - accuracy: 0.7725\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.5124 - accuracy: 0.7678\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.5157 - accuracy: 0.7678\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.5126 - accuracy: 0.7701\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.5122 - accuracy: 0.7725\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.5138 - accuracy: 0.7701\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.5119 - accuracy: 0.7725\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.5163 - accuracy: 0.7749\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.5161 - accuracy: 0.7725\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.5154 - accuracy: 0.7749\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.5173 - accuracy: 0.7630\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.5117 - accuracy: 0.7701\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.5056 - accuracy: 0.7749\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.5078 - accuracy: 0.7749\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.5074 - accuracy: 0.7749\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.5077 - accuracy: 0.7725\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.5052 - accuracy: 0.7749\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.5006 - accuracy: 0.7749\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.5017 - accuracy: 0.7773\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.5069 - accuracy: 0.7725\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.5092 - accuracy: 0.7678\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4987 - accuracy: 0.7773\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.5045 - accuracy: 0.7749\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4989 - accuracy: 0.7773\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4963 - accuracy: 0.7773\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4991 - accuracy: 0.7773\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4932 - accuracy: 0.7773\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4912 - accuracy: 0.7820\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4926 - accuracy: 0.7796\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4918 - accuracy: 0.7773\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4869 - accuracy: 0.7773\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4900 - accuracy: 0.7867\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4920 - accuracy: 0.7891\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4928 - accuracy: 0.7938\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4996 - accuracy: 0.7773\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4991 - accuracy: 0.7986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bbaaf6128>"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5182 - accuracy: 0.7447\n",
      "Normal Neural Network 6a - Loss: 0.5848448889475342, Accuracy: 0.7446808218955994\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 6a - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6c Results\n",
    "\n",
    "Model: \"sequential_20\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_65 (Dense)             (None, 100)               500       \n",
    "_________________________________________________________________\n",
    "dense_66 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_67 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_68 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 20,902\n",
    "Trainable params: 20,902\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.5182 - accuracy: 0.7447\n",
    "Normal Neural Network 6a - Loss: 0.5848448889475342, Accuracy: 0.7446808218955994\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
