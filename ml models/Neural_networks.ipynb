{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.17022005e-01, 7.20324493e-01, 1.14374817e-04])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the seed value for the notebook so the results are reproducible\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "#wanted to take a look\n",
    "np.random.rand(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up multiworker runs would be a bit more work here, see: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>TotalIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5720.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3076.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>208000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>2546.0</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4886.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3276.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3276.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4009.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4158.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4867.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>126000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5243.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2393.0</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98000.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0         0        1           0          1              0           5720.0   \n",
       "1         0        1           1          1              0           3076.0   \n",
       "2         0        1           2          1              0           5000.0   \n",
       "3         0        1           2          1              0           2340.0   \n",
       "4         0        0           0          0              0           3276.0   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "340       0        1           3          0              1           4009.0   \n",
       "341       0        1           0          1              0           4158.0   \n",
       "342       0        0           0          1              0           3250.0   \n",
       "343       0        1           0          1              0           5000.0   \n",
       "344       0        0           0          1              1           9200.0   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0                  0.0    110000.0             360.0               1   \n",
       "1               1500.0    126000.0             360.0               1   \n",
       "2               1800.0    208000.0             360.0               1   \n",
       "3               2546.0    100000.0             360.0               0   \n",
       "4                  0.0     78000.0             360.0               1   \n",
       "..                 ...         ...               ...             ...   \n",
       "340             1777.0    113000.0             360.0               1   \n",
       "341              709.0    115000.0             360.0               1   \n",
       "342             1993.0    126000.0             360.0               0   \n",
       "343             2393.0    158000.0             360.0               1   \n",
       "344                0.0     98000.0             180.0               1   \n",
       "\n",
       "     Property_Area  TotalIncome  \n",
       "0                2       5720.0  \n",
       "1                2       4576.0  \n",
       "2                2       6800.0  \n",
       "3                2       4886.0  \n",
       "4                2       3276.0  \n",
       "..             ...          ...  \n",
       "340              2       5786.0  \n",
       "341              2       4867.0  \n",
       "342              1       5243.0  \n",
       "343              0       7393.0  \n",
       "344              0       9200.0  \n",
       "\n",
       "[345 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(os.path.join('../data', 'cleanLoanDataValidationAllIncome.csv'))\n",
    "pd.set_option('display.max_columns', None)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "      <th>TotalIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4583.0</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6091.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2583.0</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4941.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5417.0</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8072.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8312.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4583.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133000.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4583.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>563 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Married  Dependents  Education  Self_Employed  ApplicantIncome  \\\n",
       "0         0        1           1          1              0           4583.0   \n",
       "1         0        1           0          1              1           3000.0   \n",
       "2         0        1           0          0              0           2583.0   \n",
       "3         0        0           0          1              0           6000.0   \n",
       "4         0        1           2          1              1           5417.0   \n",
       "..      ...      ...         ...        ...            ...              ...   \n",
       "558       1        0           0          1              0           2900.0   \n",
       "559       0        1           3          1              0           4106.0   \n",
       "560       0        1           1          1              0           8072.0   \n",
       "561       0        1           2          1              0           7583.0   \n",
       "562       1        0           0          1              1           4583.0   \n",
       "\n",
       "     CoapplicantIncome  LoanAmount  Loan_Amount_Term  Credit_History  \\\n",
       "0               1508.0    128000.0             360.0               1   \n",
       "1                  0.0     66000.0             360.0               1   \n",
       "2               2358.0    120000.0             360.0               1   \n",
       "3                  0.0    141000.0             360.0               1   \n",
       "4               4196.0    267000.0             360.0               1   \n",
       "..                 ...         ...               ...             ...   \n",
       "558                0.0     71000.0             360.0               1   \n",
       "559                0.0     40000.0             180.0               1   \n",
       "560              240.0    253000.0             360.0               1   \n",
       "561                0.0    187000.0             360.0               1   \n",
       "562                0.0    133000.0             360.0               0   \n",
       "\n",
       "     Property_Area  Loan_Status  TotalIncome  \n",
       "0                0            0       6091.0  \n",
       "1                2            1       3000.0  \n",
       "2                2            1       4941.0  \n",
       "3                2            1       6000.0  \n",
       "4                2            1       9613.0  \n",
       "..             ...          ...          ...  \n",
       "558              0            1       2900.0  \n",
       "559              0            1       4106.0  \n",
       "560              2            1       8312.0  \n",
       "561              2            1       7583.0  \n",
       "562              1            0       4583.0  \n",
       "\n",
       "[563 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(os.path.join('../data', 'cleanLoanDataTrainAllIncome.csv'))\n",
    "pd.set_option('display.max_columns', None)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1a: Total income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 10) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", \"ApplicantIncome\", \"CoapplicantIncome\"], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=10))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,402\n",
      "Trainable params: 11,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 2s - loss: 0.6489 - accuracy: 0.6232\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5766 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5488 - accuracy: 0.7204\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5331 - accuracy: 0.7559\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5401 - accuracy: 0.7536\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5305 - accuracy: 0.7725\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5165 - accuracy: 0.7725\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5122 - accuracy: 0.7749\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5171 - accuracy: 0.7725\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5096 - accuracy: 0.7773\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5057 - accuracy: 0.7773\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5026 - accuracy: 0.7796\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5018 - accuracy: 0.7820\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4972 - accuracy: 0.7796\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4965 - accuracy: 0.7796\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4942 - accuracy: 0.7867\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4908 - accuracy: 0.7844\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4926 - accuracy: 0.7820\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4888 - accuracy: 0.7891\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4857 - accuracy: 0.7820\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4827 - accuracy: 0.7891\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4812 - accuracy: 0.7915\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4810 - accuracy: 0.7962\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4777 - accuracy: 0.7915\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4771 - accuracy: 0.7867\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4723 - accuracy: 0.7938\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4703 - accuracy: 0.7915\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4704 - accuracy: 0.7938\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4670 - accuracy: 0.7962\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4653 - accuracy: 0.7986\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4661 - accuracy: 0.7938\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4605 - accuracy: 0.8009\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4585 - accuracy: 0.7915\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4553 - accuracy: 0.8057\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4549 - accuracy: 0.8009\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4607 - accuracy: 0.8009\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4496 - accuracy: 0.8033\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4469 - accuracy: 0.8033\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4482 - accuracy: 0.8057\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4483 - accuracy: 0.8152\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4363 - accuracy: 0.8152\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4342 - accuracy: 0.8104\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4394 - accuracy: 0.8152\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4382 - accuracy: 0.8152\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4278 - accuracy: 0.8152\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4298 - accuracy: 0.8270\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4279 - accuracy: 0.8294\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4243 - accuracy: 0.8294\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4263 - accuracy: 0.8246\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4204 - accuracy: 0.8223\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4152 - accuracy: 0.8365\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4227 - accuracy: 0.8294\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4233 - accuracy: 0.8246\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4118 - accuracy: 0.8318\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4097 - accuracy: 0.8341\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4080 - accuracy: 0.8318\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4042 - accuracy: 0.8246\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4068 - accuracy: 0.8294\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4088 - accuracy: 0.8318\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4078 - accuracy: 0.8341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feda8b32f60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.6149 - accuracy: 0.7021\n",
      "Normal Neural Network 1 - Loss: 0.6946593983799008, Accuracy: 0.7021276354789734\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1 - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run results\n",
    "\n",
    "Model: \"sequential_1\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_3 (Dense)              (None, 100)               1100      \n",
    "_________________________________________________________________\n",
    "dense_4 (Dense)              (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_5 (Dense)              (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,402\n",
    "Trainable params: 11,402\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 0.5452 - accuracy: 0.7092\n",
    "Normal Neural Network 1 - Loss: 0.6671343234413905, Accuracy: 0.7092198729515076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1b: Separate income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 11) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", \"TotalIncome\"], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=11))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,502\n",
      "Trainable params: 11,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6895 - accuracy: 0.5427\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5816 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5676 - accuracy: 0.7014\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5460 - accuracy: 0.7275\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5302 - accuracy: 0.7464\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5220 - accuracy: 0.7607\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5174 - accuracy: 0.7678\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5155 - accuracy: 0.7701\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5126 - accuracy: 0.7678\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5126 - accuracy: 0.7701\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5077 - accuracy: 0.7749\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5045 - accuracy: 0.7749\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5039 - accuracy: 0.7796\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4996 - accuracy: 0.7796\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4968 - accuracy: 0.7773\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4956 - accuracy: 0.7773\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4928 - accuracy: 0.7796\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4907 - accuracy: 0.7796\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4893 - accuracy: 0.7773\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4891 - accuracy: 0.7844\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4845 - accuracy: 0.7796\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4866 - accuracy: 0.7867\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4768 - accuracy: 0.7796\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4757 - accuracy: 0.7820\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4737 - accuracy: 0.7867\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4717 - accuracy: 0.7867\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4686 - accuracy: 0.7915\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4663 - accuracy: 0.7891\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4662 - accuracy: 0.7915\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4606 - accuracy: 0.7844\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4592 - accuracy: 0.7938\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4547 - accuracy: 0.7915\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4605 - accuracy: 0.7986\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4517 - accuracy: 0.8033\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4469 - accuracy: 0.8081\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4422 - accuracy: 0.8175\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4386 - accuracy: 0.8104\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4421 - accuracy: 0.8057\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4445 - accuracy: 0.8175\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4293 - accuracy: 0.8175\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4287 - accuracy: 0.8199\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4276 - accuracy: 0.8223\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4245 - accuracy: 0.8223\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4299 - accuracy: 0.8246\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4174 - accuracy: 0.8270\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4205 - accuracy: 0.8246\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4137 - accuracy: 0.8318\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4223 - accuracy: 0.8270\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4103 - accuracy: 0.8318\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4069 - accuracy: 0.8365\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4063 - accuracy: 0.8223\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4111 - accuracy: 0.8246\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4001 - accuracy: 0.8412\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.3939 - accuracy: 0.8365\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.3957 - accuracy: 0.8389\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.3902 - accuracy: 0.8223\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3944 - accuracy: 0.8436\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3865 - accuracy: 0.8460\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3867 - accuracy: 0.8341\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3841 - accuracy: 0.8365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feda8c85b00>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.6404 - accuracy: 0.6667\n",
      "Normal Neural Network 1 - Loss: 0.7258663308535908, Accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1 - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b results\n",
    "Model: \"sequential_5\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_16 (Dense)             (None, 100)               1200      \n",
    "_________________________________________________________________\n",
    "dense_17 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_18 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,502\n",
    "Trainable params: 11,502\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.5967 - accuracy: 0.6879\n",
    "Normal Neural Network 1 - Loss: 0.6984488072124779, Accuracy: 0.6879432797431946"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second run: take out Loan_Amount_Term column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 9) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\"], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=9))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,302\n",
      "Trainable params: 11,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6070 - accuracy: 0.7014\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5663 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5526 - accuracy: 0.7109\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5403 - accuracy: 0.7062\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5313 - accuracy: 0.7417\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5252 - accuracy: 0.7701\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5204 - accuracy: 0.7725\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5144 - accuracy: 0.7773\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5232 - accuracy: 0.7725\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5125 - accuracy: 0.7749\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5054 - accuracy: 0.7773\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5071 - accuracy: 0.7773\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5035 - accuracy: 0.7773\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5031 - accuracy: 0.7796\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4962 - accuracy: 0.7773\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4967 - accuracy: 0.7773\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4975 - accuracy: 0.7844\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4917 - accuracy: 0.7773\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4906 - accuracy: 0.7773\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4873 - accuracy: 0.7820\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4859 - accuracy: 0.7796\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4819 - accuracy: 0.7820\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4778 - accuracy: 0.7796\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4790 - accuracy: 0.7844\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4740 - accuracy: 0.7915\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4714 - accuracy: 0.7915\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4706 - accuracy: 0.7867\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4687 - accuracy: 0.7915\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4631 - accuracy: 0.7938\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4629 - accuracy: 0.7938\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4582 - accuracy: 0.7962\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4589 - accuracy: 0.7891\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4534 - accuracy: 0.7915\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4514 - accuracy: 0.8033\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4484 - accuracy: 0.8033\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4446 - accuracy: 0.8009\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4425 - accuracy: 0.8128\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4455 - accuracy: 0.8081\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4381 - accuracy: 0.8081\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4356 - accuracy: 0.8175\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4348 - accuracy: 0.8104\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4321 - accuracy: 0.8128\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4284 - accuracy: 0.8081\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4286 - accuracy: 0.8128\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4231 - accuracy: 0.8104\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4328 - accuracy: 0.8294\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4229 - accuracy: 0.8223\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4142 - accuracy: 0.8294\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4137 - accuracy: 0.8199\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4107 - accuracy: 0.8318\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4069 - accuracy: 0.8318\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4055 - accuracy: 0.8270\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4052 - accuracy: 0.8270\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4040 - accuracy: 0.8223\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4110 - accuracy: 0.8318\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4010 - accuracy: 0.8341\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3975 - accuracy: 0.8436\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3944 - accuracy: 0.8365\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3925 - accuracy: 0.8389\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3959 - accuracy: 0.8389\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fed88ed3828>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5383 - accuracy: 0.6879\n",
      "Normal Neural Network 1 - Loss: 0.6641574151127051, Accuracy: 0.6879432797431946\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1 - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \"sequential_2\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_6 (Dense)              (None, 100)               1000      \n",
    "_________________________________________________________________\n",
    "dense_7 (Dense)              (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_8 (Dense)              (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,302\n",
    "Trainable params: 11,302\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 0.5926 - accuracy: 0.6950\n",
    "Normal Neural Network 1 - Loss: 0.6865134027832789, Accuracy: 0.695035457611084\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b: Separate income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 10) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'Loan_Amount_Term', \"TotalIncome\"], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=10))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,402\n",
      "Trainable params: 11,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6205 - accuracy: 0.6659\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5706 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5544 - accuracy: 0.7156\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5407 - accuracy: 0.7464\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5276 - accuracy: 0.7488\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5225 - accuracy: 0.7607\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5179 - accuracy: 0.7725\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5163 - accuracy: 0.7725\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5174 - accuracy: 0.7749\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5072 - accuracy: 0.7773\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5084 - accuracy: 0.7773\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5063 - accuracy: 0.7749\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5018 - accuracy: 0.7773\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4968 - accuracy: 0.7773\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5006 - accuracy: 0.7773\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4957 - accuracy: 0.7773\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4913 - accuracy: 0.7773\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4885 - accuracy: 0.7773\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4842 - accuracy: 0.7796\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4810 - accuracy: 0.7820\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4827 - accuracy: 0.7796\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4780 - accuracy: 0.7867\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4752 - accuracy: 0.7820\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4736 - accuracy: 0.7867\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4721 - accuracy: 0.7820\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4706 - accuracy: 0.7796\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4627 - accuracy: 0.7867\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4638 - accuracy: 0.7915\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4562 - accuracy: 0.7891\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4540 - accuracy: 0.7938\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4574 - accuracy: 0.8009\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4618 - accuracy: 0.8057\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4567 - accuracy: 0.8009\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4475 - accuracy: 0.8104\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4414 - accuracy: 0.8009\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4368 - accuracy: 0.8057\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4312 - accuracy: 0.8152\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4354 - accuracy: 0.8009\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4305 - accuracy: 0.8175\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4280 - accuracy: 0.8199\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4275 - accuracy: 0.8175\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4237 - accuracy: 0.8270\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4281 - accuracy: 0.8199\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4213 - accuracy: 0.8199\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4181 - accuracy: 0.8341\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4142 - accuracy: 0.8223\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4081 - accuracy: 0.8294\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4034 - accuracy: 0.8389\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4015 - accuracy: 0.8365\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4018 - accuracy: 0.8294\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4107 - accuracy: 0.8318\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.3948 - accuracy: 0.8389\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.3907 - accuracy: 0.8460\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.3899 - accuracy: 0.8436\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.3907 - accuracy: 0.8436\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.3849 - accuracy: 0.8460\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3840 - accuracy: 0.8531\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3863 - accuracy: 0.8389\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3823 - accuracy: 0.8436\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3770 - accuracy: 0.8412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fed88d93780>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.6060 - accuracy: 0.7021\n",
      "Normal Neural Network 1 - Loss: 0.6719605242106932, Accuracy: 0.7021276354789734\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1 - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \"sequential_6\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_19 (Dense)             (None, 100)               1100      \n",
    "_________________________________________________________________\n",
    "dense_20 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_21 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,402\n",
    "Trainable params: 11,402\n",
    "Non-trainable params: 0\n",
    "    \n",
    "141/1 - 0s - loss: 0.5788 - accuracy: 0.7234\n",
    "Normal Neural Network 1 - Loss: 0.6754736462806133, Accuracy: 0.7234042286872864"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third run: take out Loan_Amount_Term and LoanAmount columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 8) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\"], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=8))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 100)               900       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,202\n",
      "Trainable params: 11,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6323 - accuracy: 0.6517\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5839 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5531 - accuracy: 0.7133\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5426 - accuracy: 0.7464\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5308 - accuracy: 0.7441\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5267 - accuracy: 0.7607\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5197 - accuracy: 0.7725\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5207 - accuracy: 0.7749\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5214 - accuracy: 0.7725\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5119 - accuracy: 0.7844\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5139 - accuracy: 0.7749\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5070 - accuracy: 0.7749\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5071 - accuracy: 0.7773\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5032 - accuracy: 0.7773\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5012 - accuracy: 0.7773\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.5004 - accuracy: 0.7844\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4986 - accuracy: 0.7773\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4991 - accuracy: 0.7773\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4935 - accuracy: 0.7844\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4919 - accuracy: 0.7844\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4890 - accuracy: 0.7820\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4902 - accuracy: 0.7844\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4932 - accuracy: 0.7796\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4824 - accuracy: 0.7773\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4902 - accuracy: 0.7867\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4900 - accuracy: 0.7867\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4805 - accuracy: 0.7891\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4788 - accuracy: 0.7867\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4812 - accuracy: 0.7867\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4744 - accuracy: 0.7915\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4691 - accuracy: 0.7915\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4684 - accuracy: 0.7891\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4693 - accuracy: 0.7844\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4634 - accuracy: 0.7938\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4627 - accuracy: 0.7986\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4649 - accuracy: 0.7938\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4615 - accuracy: 0.7938\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4563 - accuracy: 0.7938\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4580 - accuracy: 0.7986\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4627 - accuracy: 0.7986\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4539 - accuracy: 0.8081\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4479 - accuracy: 0.8033\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4464 - accuracy: 0.8128\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4488 - accuracy: 0.8033\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4422 - accuracy: 0.8081\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4423 - accuracy: 0.8081\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4421 - accuracy: 0.8081\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4376 - accuracy: 0.8081\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4397 - accuracy: 0.8152\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4368 - accuracy: 0.8057\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4361 - accuracy: 0.8175\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4321 - accuracy: 0.8057\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4332 - accuracy: 0.8104\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4329 - accuracy: 0.8152\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4323 - accuracy: 0.8081\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4245 - accuracy: 0.8223\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4262 - accuracy: 0.8175\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4235 - accuracy: 0.8223\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4237 - accuracy: 0.8199\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.4165 - accuracy: 0.8270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7feda8f80eb8>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.5502 - accuracy: 0.6950\n",
      "Normal Neural Network 1 - Loss: 0.6399033718498041, Accuracy: 0.695035457611084\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1 - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \"sequential_3\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_9 (Dense)              (None, 100)               900       \n",
    "_________________________________________________________________\n",
    "dense_10 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_11 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 11,202\n",
    "Trainable params: 11,202\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.5538 - accuracy: 0.7092\n",
    "Normal Neural Network 1 - Loss: 0.6326239667040237, Accuracy: 0.7092198729515076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b: Separate income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 9) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"TotalIncome\"], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=9))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,302\n",
      "Trainable params: 11,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6019 - accuracy: 0.7014\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5664 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5441 - accuracy: 0.7085\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5357 - accuracy: 0.7630\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5276 - accuracy: 0.7796\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5195 - accuracy: 0.7725\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5186 - accuracy: 0.7749\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5165 - accuracy: 0.7773\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5121 - accuracy: 0.7773\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5155 - accuracy: 0.7773\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5098 - accuracy: 0.7749\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5098 - accuracy: 0.7773\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.5085 - accuracy: 0.7773\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.5098 - accuracy: 0.7725\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5018 - accuracy: 0.7773\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4997 - accuracy: 0.7773\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4973 - accuracy: 0.7773\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4987 - accuracy: 0.7773\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4921 - accuracy: 0.7773\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4907 - accuracy: 0.7773\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4896 - accuracy: 0.7773\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4842 - accuracy: 0.7773\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4885 - accuracy: 0.7773\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4814 - accuracy: 0.7796\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4788 - accuracy: 0.7796\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4769 - accuracy: 0.7844\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4736 - accuracy: 0.7844\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4761 - accuracy: 0.7867\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4706 - accuracy: 0.7891\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4665 - accuracy: 0.7938\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4639 - accuracy: 0.7962\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4631 - accuracy: 0.8057\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4591 - accuracy: 0.8009\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4580 - accuracy: 0.8104\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4537 - accuracy: 0.7986\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4487 - accuracy: 0.8057\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4468 - accuracy: 0.8081\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4430 - accuracy: 0.8033\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4464 - accuracy: 0.8009\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4392 - accuracy: 0.8081\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4381 - accuracy: 0.8175\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4384 - accuracy: 0.8104\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4303 - accuracy: 0.8175\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4265 - accuracy: 0.8270\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4276 - accuracy: 0.8199\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4212 - accuracy: 0.8128\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.4339 - accuracy: 0.8270\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.4242 - accuracy: 0.8199\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.4179 - accuracy: 0.8223\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.4178 - accuracy: 0.8318\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.4157 - accuracy: 0.8175\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.4241 - accuracy: 0.8318\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.4303 - accuracy: 0.8104\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.4098 - accuracy: 0.8341\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.4050 - accuracy: 0.8199\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.4114 - accuracy: 0.8294\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.4061 - accuracy: 0.8246\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.4041 - accuracy: 0.8270\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.4035 - accuracy: 0.8365\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3991 - accuracy: 0.8365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fedb9483e48>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.7318 - accuracy: 0.6667\n",
      "Normal Neural Network 1 - Loss: 0.7879310296782365, Accuracy: 0.6666666865348816\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1 - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth run: take out Loan_Amount_Term and LoanAmount columns, add a layer - no change in accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 8) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"ApplicantIncome\", \"CoapplicantIncome\"], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=8))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 100)               900       \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 21,302\n",
      "Trainable params: 21,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6280 - accuracy: 0.6422\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5633 - accuracy: 0.6991\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5380 - accuracy: 0.7488\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5219 - accuracy: 0.7701\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5181 - accuracy: 0.7701\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5171 - accuracy: 0.7773\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5093 - accuracy: 0.7773\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5052 - accuracy: 0.7773\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5026 - accuracy: 0.7773\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.4993 - accuracy: 0.7749\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.4995 - accuracy: 0.7725\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.4898 - accuracy: 0.7773\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.4865 - accuracy: 0.7796\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4845 - accuracy: 0.7773\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.4855 - accuracy: 0.7820\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4805 - accuracy: 0.7867\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4750 - accuracy: 0.7986\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4709 - accuracy: 0.8033\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4706 - accuracy: 0.7986\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4670 - accuracy: 0.7938\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4704 - accuracy: 0.8033\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4574 - accuracy: 0.8057\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4552 - accuracy: 0.8081\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4589 - accuracy: 0.7962\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4499 - accuracy: 0.8033\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4546 - accuracy: 0.8104\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4563 - accuracy: 0.8033\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4542 - accuracy: 0.8104\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4381 - accuracy: 0.8057\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4336 - accuracy: 0.8033\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4287 - accuracy: 0.8081\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4319 - accuracy: 0.8128\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4220 - accuracy: 0.8223\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4174 - accuracy: 0.8152\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4275 - accuracy: 0.8175\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4124 - accuracy: 0.8246\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4216 - accuracy: 0.8199\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4093 - accuracy: 0.8223\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4104 - accuracy: 0.8175\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4180 - accuracy: 0.8199\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4040 - accuracy: 0.8246\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4161 - accuracy: 0.8294\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4131 - accuracy: 0.8199\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.4021 - accuracy: 0.8294\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.4039 - accuracy: 0.8341\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.4018 - accuracy: 0.8199\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.3955 - accuracy: 0.8365\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.3938 - accuracy: 0.8341\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.3924 - accuracy: 0.8389\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.3852 - accuracy: 0.8389\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.3858 - accuracy: 0.8412\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.3856 - accuracy: 0.8389\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.3899 - accuracy: 0.8365\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.3734 - accuracy: 0.8412\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.3799 - accuracy: 0.8341\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.3914 - accuracy: 0.8389\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3797 - accuracy: 0.8412\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3820 - accuracy: 0.8365\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3718 - accuracy: 0.8389\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3620 - accuracy: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fed5a1b4080>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.9385 - accuracy: 0.6454\n",
      "Normal Neural Network 1 - Loss: 1.0012289357523547, Accuracy: 0.6453900933265686\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1 - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model: \"sequential_4\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "dense_12 (Dense)             (None, 100)               900       \n",
    "_________________________________________________________________\n",
    "dense_13 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_14 (Dense)             (None, 100)               10100     \n",
    "_________________________________________________________________\n",
    "dense_15 (Dense)             (None, 2)                 202       \n",
    "=================================================================\n",
    "Total params: 21,302\n",
    "Trainable params: 21,302\n",
    "Non-trainable params: 0\n",
    "\n",
    "141/1 - 0s - loss: 0.7248 - accuracy: 0.6809\n",
    "Normal Neural Network 1 - Loss: 0.9271682179565971, Accuracy: 0.6808510422706604\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b: Separate income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 9) (563,)\n"
     ]
    }
   ],
   "source": [
    "X = train_data.drop([\"Loan_Status\", 'LoanAmount', 'Loan_Amount_Term', \"TotalIncome\"], axis=1)\n",
    "y = train_data[\"Loan_Status\"]\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=100, activation='relu', input_dim=9))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 100)               1000      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 21,402\n",
      "Trainable params: 21,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 422 samples\n",
      "Epoch 1/60\n",
      "422/422 - 1s - loss: 0.6211 - accuracy: 0.6469\n",
      "Epoch 2/60\n",
      "422/422 - 0s - loss: 0.5736 - accuracy: 0.7014\n",
      "Epoch 3/60\n",
      "422/422 - 0s - loss: 0.5476 - accuracy: 0.7062\n",
      "Epoch 4/60\n",
      "422/422 - 0s - loss: 0.5317 - accuracy: 0.7749\n",
      "Epoch 5/60\n",
      "422/422 - 0s - loss: 0.5311 - accuracy: 0.7678\n",
      "Epoch 6/60\n",
      "422/422 - 0s - loss: 0.5294 - accuracy: 0.7701\n",
      "Epoch 7/60\n",
      "422/422 - 0s - loss: 0.5155 - accuracy: 0.7678\n",
      "Epoch 8/60\n",
      "422/422 - 0s - loss: 0.5174 - accuracy: 0.7678\n",
      "Epoch 9/60\n",
      "422/422 - 0s - loss: 0.5106 - accuracy: 0.7701\n",
      "Epoch 10/60\n",
      "422/422 - 0s - loss: 0.5070 - accuracy: 0.7701\n",
      "Epoch 11/60\n",
      "422/422 - 0s - loss: 0.5068 - accuracy: 0.7820\n",
      "Epoch 12/60\n",
      "422/422 - 0s - loss: 0.5009 - accuracy: 0.7701\n",
      "Epoch 13/60\n",
      "422/422 - 0s - loss: 0.4959 - accuracy: 0.7844\n",
      "Epoch 14/60\n",
      "422/422 - 0s - loss: 0.4922 - accuracy: 0.7773\n",
      "Epoch 15/60\n",
      "422/422 - 0s - loss: 0.5013 - accuracy: 0.7891\n",
      "Epoch 16/60\n",
      "422/422 - 0s - loss: 0.4855 - accuracy: 0.7867\n",
      "Epoch 17/60\n",
      "422/422 - 0s - loss: 0.4853 - accuracy: 0.7891\n",
      "Epoch 18/60\n",
      "422/422 - 0s - loss: 0.4761 - accuracy: 0.7938\n",
      "Epoch 19/60\n",
      "422/422 - 0s - loss: 0.4732 - accuracy: 0.7938\n",
      "Epoch 20/60\n",
      "422/422 - 0s - loss: 0.4689 - accuracy: 0.8033\n",
      "Epoch 21/60\n",
      "422/422 - 0s - loss: 0.4745 - accuracy: 0.7867\n",
      "Epoch 22/60\n",
      "422/422 - 0s - loss: 0.4678 - accuracy: 0.8104\n",
      "Epoch 23/60\n",
      "422/422 - 0s - loss: 0.4630 - accuracy: 0.7962\n",
      "Epoch 24/60\n",
      "422/422 - 0s - loss: 0.4718 - accuracy: 0.7986\n",
      "Epoch 25/60\n",
      "422/422 - 0s - loss: 0.4596 - accuracy: 0.8009\n",
      "Epoch 26/60\n",
      "422/422 - 0s - loss: 0.4474 - accuracy: 0.8057\n",
      "Epoch 27/60\n",
      "422/422 - 0s - loss: 0.4449 - accuracy: 0.8057\n",
      "Epoch 28/60\n",
      "422/422 - 0s - loss: 0.4373 - accuracy: 0.8057\n",
      "Epoch 29/60\n",
      "422/422 - 0s - loss: 0.4422 - accuracy: 0.8128\n",
      "Epoch 30/60\n",
      "422/422 - 0s - loss: 0.4325 - accuracy: 0.8128\n",
      "Epoch 31/60\n",
      "422/422 - 0s - loss: 0.4445 - accuracy: 0.8033\n",
      "Epoch 32/60\n",
      "422/422 - 0s - loss: 0.4307 - accuracy: 0.8152\n",
      "Epoch 33/60\n",
      "422/422 - 0s - loss: 0.4327 - accuracy: 0.8175\n",
      "Epoch 34/60\n",
      "422/422 - 0s - loss: 0.4180 - accuracy: 0.8199\n",
      "Epoch 35/60\n",
      "422/422 - 0s - loss: 0.4208 - accuracy: 0.8223\n",
      "Epoch 36/60\n",
      "422/422 - 0s - loss: 0.4093 - accuracy: 0.8294\n",
      "Epoch 37/60\n",
      "422/422 - 0s - loss: 0.4025 - accuracy: 0.8294\n",
      "Epoch 38/60\n",
      "422/422 - 0s - loss: 0.4054 - accuracy: 0.8294\n",
      "Epoch 39/60\n",
      "422/422 - 0s - loss: 0.4246 - accuracy: 0.8152\n",
      "Epoch 40/60\n",
      "422/422 - 0s - loss: 0.4332 - accuracy: 0.8270\n",
      "Epoch 41/60\n",
      "422/422 - 0s - loss: 0.4021 - accuracy: 0.8318\n",
      "Epoch 42/60\n",
      "422/422 - 0s - loss: 0.4012 - accuracy: 0.8223\n",
      "Epoch 43/60\n",
      "422/422 - 0s - loss: 0.4062 - accuracy: 0.8270\n",
      "Epoch 44/60\n",
      "422/422 - 0s - loss: 0.3869 - accuracy: 0.8365\n",
      "Epoch 45/60\n",
      "422/422 - 0s - loss: 0.3924 - accuracy: 0.8270\n",
      "Epoch 46/60\n",
      "422/422 - 0s - loss: 0.3952 - accuracy: 0.8436\n",
      "Epoch 47/60\n",
      "422/422 - 0s - loss: 0.3881 - accuracy: 0.8531\n",
      "Epoch 48/60\n",
      "422/422 - 0s - loss: 0.3813 - accuracy: 0.8389\n",
      "Epoch 49/60\n",
      "422/422 - 0s - loss: 0.3908 - accuracy: 0.8294\n",
      "Epoch 50/60\n",
      "422/422 - 0s - loss: 0.3850 - accuracy: 0.8365\n",
      "Epoch 51/60\n",
      "422/422 - 0s - loss: 0.3683 - accuracy: 0.8365\n",
      "Epoch 52/60\n",
      "422/422 - 0s - loss: 0.3732 - accuracy: 0.8531\n",
      "Epoch 53/60\n",
      "422/422 - 0s - loss: 0.3667 - accuracy: 0.8389\n",
      "Epoch 54/60\n",
      "422/422 - 0s - loss: 0.3696 - accuracy: 0.8412\n",
      "Epoch 55/60\n",
      "422/422 - 0s - loss: 0.3577 - accuracy: 0.8436\n",
      "Epoch 56/60\n",
      "422/422 - 0s - loss: 0.3534 - accuracy: 0.8341\n",
      "Epoch 57/60\n",
      "422/422 - 0s - loss: 0.3595 - accuracy: 0.8412\n",
      "Epoch 58/60\n",
      "422/422 - 0s - loss: 0.3553 - accuracy: 0.8460\n",
      "Epoch 59/60\n",
      "422/422 - 0s - loss: 0.3605 - accuracy: 0.8365\n",
      "Epoch 60/60\n",
      "422/422 - 0s - loss: 0.3576 - accuracy: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fedb97e87f0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/1 - 0s - loss: 0.8754 - accuracy: 0.6454\n",
      "Normal Neural Network 1 - Loss: 0.8913993539539635, Accuracy: 0.6453900933265686\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(\n",
    "    f\"Normal Neural Network 1 - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
